{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makine Öğrenmesi - Doğrusal Regresyon Modelleri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basit Doğrusal Regresyon "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#http://faculty.marshall.usc.edu/gareth-james/ISL/data.html buradan indirlebilir verisetleri\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"Advertising.csv\")\n",
    "df = df.iloc[:,1:len(df)] #burası olmasaydı indexte bi sıkıntı oluyordu. Görmek istersen burayı commente al.\n",
    "df.head() #Bağımlı değişken satış değişkeni, diğerleri bağımsız değişken.\n",
    "#bir şirketin reklam harcamaları neticesinde satışları verilmiş.\n",
    "#Yani, tv-radyo-gazetelerde yapılmış olan reklam harcamalrı sonrasında satışların ne şekilde oluştğu ifade edilmiş.\n",
    "#satışlar birimleştirilmiş. amacımız, satışları modelleyebilmek.yani reklam harcamaları neticesinde oluşan \n",
    "#satışları ne şekilde oluştuğunu modellemek.\n",
    "#Biz burada basit doğrusal regresyon incelediğimizden, buradaki bir değişkeni seçip oradan devam edeceğiz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   TV         200 non-null    float64\n",
      " 1   radio      200 non-null    float64\n",
      " 2   newspaper  200 non-null    float64\n",
      " 3   sales      200 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 6.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.jointplot(x = \"TV\", y = \"sales\", data = df, kind = \"reg\"); #burada tv ve sales kısmını seçtik. bunlar üzerinden\n",
    "# basit doğrusal reg incelemesini yapacağız. türümüz regresyon olacak dedik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "burada kabaca, satışlar ile tv arasındaki ilişkiyi görselleştirmiş olduk. burada diyor ki yani tv reklam harcamaları arttıkça, satışlarda bir artış olduğu gözlemleniyor. aralarında pozitif ve doğrusal yönde bir ilişki var.\n",
    "şimdi,bu ilişkiyi modellemiş olucaz. makine öğrenmesi yaklaşımı ile, eğer elimize bir tv harcaması değeri gelir ise, buna karşılık satışların ne olabileceğini tahmin etmeye çalışıcaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"TV\"]] #Bağımsız değişkeni x ile ifade edicez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV\n",
       "0  230.1\n",
       "1   44.5\n",
       "2   17.2\n",
       "3  151.5\n",
       "4  180.8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[[\"sales\"]] #Bağımlı değişkeni y ile ifade edeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression() #model nesnesi oluşturduk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = reg.fit(X, y) #bu modeli fit et, bu modeli kur diyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model #model nesnesini getirdi. bununla ilgili bilgi vermiş. ama biz bunun içerisinden bişeyler almak istiyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinearRegression()'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_check_n_features',\n",
       " '_decision_function',\n",
       " '_estimator_type',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_preprocess_data',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_residues',\n",
       " '_set_intercept',\n",
       " '_validate_data',\n",
       " 'coef_',\n",
       " 'copy_X',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'get_params',\n",
       " 'intercept_',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'normalize',\n",
       " 'positive',\n",
       " 'predict',\n",
       " 'rank_',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'singular_']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model) #burada, bu nesnenin içerisinden alabileceğimiz bazı bilgileri gösteriyor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hatırlarsak, basit doğrusal regresyonda bir b0 sabitimiz vardı ve bir de b1 katsayımız vardı. Yukarıda gözüken intercept şeklinde ifade edilen şey sabittir. bunun ile bu sabiti çekebiliriz. coef ise katsayı demektir. modele ilişkin b1'de buradan çekebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.03259355])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_ #Sabitimiz. b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04753664]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_ #Katsayımız. b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.611875050850071"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rkare, modelin skorunu ifade ediyor. r^2 = Bağımlı değişkendeki değişikliğin, bağımsız değişkenlerce açıklanma yüzdesi.\n",
    "#Yani bu örneğimizde, satışlardaki değişikliğin, yaklaşık %60'ı bağımsız değişkence açıklanmaktadır.\n",
    "# satışların içinde bir varyans var, bir değişim var, işte bu satış değişkeninin içerisindeki değişimi, burada kullanmış\n",
    "#olduğumuz tv değişkeni, işte bu değişimiz yaklaşık %60'ını açıklamaktadır.\n",
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dolayısıyla, elimizdeki verisetlerinde doğrusal regresyon modelleri ile ilgilendiğimizde, r^2 değerine baktığımızda şu bilgilyi elde ederiz: elimizdeki bağımsız değişkenleri kullandığımızda, bağımlı değişkendeki değişimin %kaçını açıklayabiliyoruz şeklinde bize değerli bir bilgi sunmakta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "g = sns.regplot(df[\"TV\"], df[\"sales\"], ci=None, scatter_kws={'color':'r', 's':9}) #Burada bir regresyon görselleştirmesi yapacağız dedik\n",
    "#Tv ve sales değişkeni üzerinden, güven aralığı koyma dedik(ci=none), sonra da renklendirme parametreleri girdik.\n",
    "g.set_title(\"Model Denklemi: Sales = 7.03 + TV*0.05\")\n",
    "g.set_ylabel(\"Satış Sayısı\")\n",
    "g.set_xlabel(\"TV Harcamaları\")\n",
    "plt.xlim(-10,310) #x ekseni limitlerini ayarladık.\n",
    "plt.ylim(bottom=0); #y eksenini de 0 dan başlattık.\n",
    "# GÖRSELLEŞTİRME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulduklarımızı görselleştirdik. Sales değişkeni ile tv değişkeni arasındaki ilişki budur. Bu bir saçılım grafiği. Ortadaki mavi çizgi ise bulmuş olduğumuz model denklemi. Aşağıda da denklem yazmakta. Tahmin etmek ne demek? Biz veriyi kullanarak, verisetinin içerisinden bir sabit ve bir diğer sabiti bulmuş olduk. Ve bunlar belirli değerlerle çarpıldğında, burda 0.05 sabit,tv değişken, iki tane sabiti bulmuş olduk, tv değeri geldiğinde örneğin 250 değeri geldiğinde, 250 değeri 0.05 ile çarpılıyor, üzerine 7.03 eklenip satışlardaki karşılığı gelmiş oluyor. Yani biz aslında burada tahmin yapacak bir fonk üretmiş olduk.\n",
    "\n",
    "Peki bununla nasıl bir tahmin işlemi gerçekleştiricez? Neden tahmin etmeye ihtiyacımız var? Ben bu yıl tv reklam harcamalarına ne kadar harcama-yatırım yaparsam satışlarım ne olur cevabının yanıtını veriyoruz. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sales = 7.03 + 0.05*TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.87613922]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_ + model.coef_*165 #Mesela 165 birimlik tv harcaması yaparsam satışlarım kaç birim olur? Tahmin ettik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grafik üzerinden bakarsak, 165 üzerinden yukarı doğru çıkacağız, b0'ı alacak, b1 ile eğimini alacak, sonuçta 165 değeriindeki doğru çizgimize ulaşacak, karşılığındaki y değerini verecek. Bizim bütün amacımız bu doğruyu bulmaktı. Bu doğruyu oluşturan şey zaten eğim ve yükseklik(sabit). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14.87613922]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([[165]]) #diyoruz ki bu modeli kullanarak, yukarıda model'i atamıştık nesneye, predict et. bizden bağımsız değişken\n",
    "# değerini istiyor. Yani tv harcamaları değerini istiyor. biz buraya 400 de girsek, model bize tahminde bulunur. zira artık patter'i\n",
    "# öğrendi tahmin yapabilir. elde olmayan değerler bile girilmiş olsa, tahmin yapılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeni_veri = [[5],[15],[30]] #mesela 3 harcama tahmini yapmak istedik. yani mesela 5 birimlik tv harcaması 15 ve 30 birimlik tv harcaması\n",
    "#yapsak ne kadar satış olur bunlara bakalım dendi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.27027675],\n",
       "       [7.74564316],\n",
       "       [8.45869276]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(yeni_veri) #kurmuş olduğum modeli kullanarak tahminde bulun diyoruz tekrar. hepsini tahmin etti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artıklar ve Makine Öğrenmesindeki Önemi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MSE: Hata Kareler Ortalaması**\n",
    "\n",
    "**RMSE: Hata Kareler Ortalamasının Karekökü**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimizde bir algortma var. Örneğin önceki bölümde, basit doğrusal regresyon modeli idi. Veri içerisinden parametreleri öğrendik. Bu parametreleri kullanarak, tahminde bulunduk. Şimdi elimizde bir gerçek değerler var, bir de tahmin edilen değerler var. Amaç: gerçek değerler ile, tahmin edilen değerler arasındaki farkları minimum yapmak. Ve bizim, kurmuş olduğumuz modellerin başarısını değerlendirmek için, göz önünde bulunduracak olduğumuz metrikler de buna yönelik metrikler. Yani mesela, regresyon problemleri için MSE ve RMSE değerlerini kullanacağız. Bunlar yine gerçek değerler ile, tahmin edilen değerler arasındaki farkların ortaya çıkardığı yapıyı genelleştirerek bize sunan bir hata ölçüm metriği. Sınıflandırma problemlerinde de, doğru sınıflandırma oranına bakacağız.\n",
    "\n",
    "Şimdi elimizde gerçek değerler var, tahmin edilen değerler var, bunların arasındaki farkların üzerinden optimizasyon işlemleri yapacağız. Modelleme mantığını anlamak önemli, tahmin etme mantığını anlamak çok önemli, fakat orta-ileri seviyede arka tarafta algoritma optimizasyonu dediğimiz şeyin ne yaptığını anlamak çok daha önemli. ileriki dönemler için. Mesela lightgbm, xgboost gibi algoritmaların arka tarafta yaptığı işlemler aslında artıklara-hatalara odaklanmak. Hatalar, gerçek değerler ile, tahmin edilen değerler arasındaki farklardır. İşte o algoritmalar, bu hatalara odaklanarak bunları optimize etmeye çalışmaktadır. Yapay sinir ağları, bunlara odaklanarak algoritmanın daha performanslı olmasını sağlamaya çalışır. Dolayısıyla bizim de burada, daha makine öğrenmesinin en başında artık dediğimiz hata dediğimiz kavramı çok iyi pekiştirmemiz gerekiyor.\n",
    "Şimdi, verisetimizi x ve y olarak ikiye ayırmıştık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales\n",
       "0   22.1\n",
       "1   10.4\n",
       "2    9.3\n",
       "3   18.5\n",
       "4   12.9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head() #bunlar gerçek değerler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.97077451],\n",
       "       [ 9.14797405],\n",
       "       [ 7.85022376],\n",
       "       [14.23439457],\n",
       "       [15.62721814],\n",
       "       [ 7.44616232]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)[0:6] # bir de biz, model kurmuştuk. Bağımsız değişken değerlerimizi yerine koyup, haydi ağımlı değişkeni tahmin edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yukarıdaki y, verisetimizin orjinal halindeki bağımlı değişkenimizin değerleri. Burası ise, kurmuş olduğumuz modeli kullanarak,\n",
    "# bir tahmin etme işlemi gerçekleştirdik.Tahmin etmek için bağımsız değişkenlerimizin değerleri zaten veriseitmizin kendisi. x,yani\n",
    "# buradaki tv harcamaları. tahmin et, tv harcamaları ile satışların ne olacağını dedik. Satışlar tahmin edildi. Yani burası tahmin edilen\n",
    "# Yukarıdaki y ise gerçek değerler.\n",
    "# Şşimdi elimizde bir gerçek değerler var, bir de tahmin edilen değerler var. Bakalım ne kadar Başarılı bir iş yapmışız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gercek_y = y[0:10] #ilk 10 birim içerisinden bu başarıyı test edelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tahmin_edilen_y = pd.DataFrame(model.predict(X)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatalar = pd.concat([gercek_y, tahmin_edilen_y], axis = 1) #Bu ikisini df haline getirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatalar.columns = [\"gercek_y\",\"tahmin_edilen_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gercek_y</th>\n",
       "      <th>tahmin_edilen_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "      <td>17.970775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "      <td>9.147974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "      <td>7.850224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>14.234395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "      <td>15.627218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.2</td>\n",
       "      <td>7.446162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.8</td>\n",
       "      <td>9.765950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.2</td>\n",
       "      <td>12.746498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.8</td>\n",
       "      <td>7.441409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.6</td>\n",
       "      <td>16.530414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gercek_y  tahmin_edilen_y\n",
       "0      22.1        17.970775\n",
       "1      10.4         9.147974\n",
       "2       9.3         7.850224\n",
       "3      18.5        14.234395\n",
       "4      12.9        15.627218\n",
       "5       7.2         7.446162\n",
       "6      11.8         9.765950\n",
       "7      13.2        12.746498\n",
       "8       4.8         7.441409\n",
       "9      10.6        16.530414"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Şimdi artık ne demek? hataların içerisine yeni bir değişken ekliyoruz. buna hata diyoruz, artık da diyebiliriz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatalar[\"hata\"] = hatalar[\"gercek_y\"] - hatalar[\"tahmin_edilen_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gercek_y</th>\n",
       "      <th>tahmin_edilen_y</th>\n",
       "      <th>hata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "      <td>17.970775</td>\n",
       "      <td>4.129225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "      <td>9.147974</td>\n",
       "      <td>1.252026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "      <td>7.850224</td>\n",
       "      <td>1.449776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>14.234395</td>\n",
       "      <td>4.265605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "      <td>15.627218</td>\n",
       "      <td>-2.727218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.2</td>\n",
       "      <td>7.446162</td>\n",
       "      <td>-0.246162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.8</td>\n",
       "      <td>9.765950</td>\n",
       "      <td>2.034050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.2</td>\n",
       "      <td>12.746498</td>\n",
       "      <td>0.453502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.8</td>\n",
       "      <td>7.441409</td>\n",
       "      <td>-2.641409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.6</td>\n",
       "      <td>16.530414</td>\n",
       "      <td>-5.930414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gercek_y  tahmin_edilen_y      hata\n",
       "0      22.1        17.970775  4.129225\n",
       "1      10.4         9.147974  1.252026\n",
       "2       9.3         7.850224  1.449776\n",
       "3      18.5        14.234395  4.265605\n",
       "4      12.9        15.627218 -2.727218\n",
       "5       7.2         7.446162 -0.246162\n",
       "6      11.8         9.765950  2.034050\n",
       "7      13.2        12.746498  0.453502\n",
       "8       4.8         7.441409 -2.641409\n",
       "9      10.6        16.530414 -5.930414"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatalar \n",
    "# Bazıları pozitif yönlü, bazıları negatif yönlü hatalarımıza eriştik. Yani mesela bir satış 22,1 iken biz 17,9 demişiz.\n",
    "# her bir gözlem birimi için yapılan hatalar burada verilmiş. bunlar bizim gözlemler üzerinde yapmış olduğumuz hatalar.\n",
    "# Peki şimdi şöyle bir merakımız olduğunu düşünelim: her birisi için bir hatamız var tamam ama, bize ortalama bir hata lazım olsun.\n",
    "# ve örneğin, öğrenmiş olduğumuz mse değeri üzerinden bir hata hesaplamak istediğimizi düşünelim. mse'de hataların karesini alıyorduk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hatalar[\"hata_kareler\"] = hatalar[\"hata\"]**2 # bu kareyi neden alıyorduk? buradaki - ve + değerler birbirini götürmesin diye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gercek_y</th>\n",
       "      <th>tahmin_edilen_y</th>\n",
       "      <th>hata</th>\n",
       "      <th>hata_kareler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "      <td>17.970775</td>\n",
       "      <td>4.129225</td>\n",
       "      <td>17.050503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "      <td>9.147974</td>\n",
       "      <td>1.252026</td>\n",
       "      <td>1.567569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "      <td>7.850224</td>\n",
       "      <td>1.449776</td>\n",
       "      <td>2.101851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "      <td>14.234395</td>\n",
       "      <td>4.265605</td>\n",
       "      <td>18.195390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "      <td>15.627218</td>\n",
       "      <td>-2.727218</td>\n",
       "      <td>7.437719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.2</td>\n",
       "      <td>7.446162</td>\n",
       "      <td>-0.246162</td>\n",
       "      <td>0.060596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.8</td>\n",
       "      <td>9.765950</td>\n",
       "      <td>2.034050</td>\n",
       "      <td>4.137358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.2</td>\n",
       "      <td>12.746498</td>\n",
       "      <td>0.453502</td>\n",
       "      <td>0.205664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.8</td>\n",
       "      <td>7.441409</td>\n",
       "      <td>-2.641409</td>\n",
       "      <td>6.977040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.6</td>\n",
       "      <td>16.530414</td>\n",
       "      <td>-5.930414</td>\n",
       "      <td>35.169814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gercek_y  tahmin_edilen_y      hata  hata_kareler\n",
       "0      22.1        17.970775  4.129225     17.050503\n",
       "1      10.4         9.147974  1.252026      1.567569\n",
       "2       9.3         7.850224  1.449776      2.101851\n",
       "3      18.5        14.234395  4.265605     18.195390\n",
       "4      12.9        15.627218 -2.727218      7.437719\n",
       "5       7.2         7.446162 -0.246162      0.060596\n",
       "6      11.8         9.765950  2.034050      4.137358\n",
       "7      13.2        12.746498  0.453502      0.205664\n",
       "8       4.8         7.441409 -2.641409      6.977040\n",
       "9      10.6        16.530414 -5.930414     35.169814"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.290350329638104"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(hatalar[\"hata_kareler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# burada yaptığımız şey: 10 tane gözlem birimi üzerinden kendimiz el yordamıyla hata kareler ortalamasını hesapladık yani bu, \n",
    "# bu modelimizin veriler üzerindeki testi sonucunda elde ettiğimiz ortalama hatamız.\n",
    "# Yani bunu yaptığımızda şunu diyor oluruz: bizim modelimiz şu kadar başarılı, hata kareler ortalaması 9.22 birim demiş oluruz. \n",
    "# biz bunu 10 gözlem için yaptık. İlerleyen bölümler bu hata kareler ortlaması ve bunun karekökü gibi değerleri, daha büyük ölçekli \n",
    "# pandasın numpy bize sunduğu fonksiyonlar aracılığıyla ölçmüş olacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Çoklu Doğrusal Regresyon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "0  230.1   37.8       69.2   22.1\n",
       "1   44.5   39.3       45.1   10.4\n",
       "2   17.2   45.9       69.3    9.3\n",
       "3  151.5   41.3       58.5   18.5\n",
       "4  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#http://faculty.marshall.usc.edu/gareth-james/ISL/data.html\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"Advertising.csv\")\n",
    "df = df.iloc[:,1:len(df)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('sales', axis=1) #Bağımsız değişkenler\n",
    "y = df[[\"sales\"]] #Bağımlı değişken(2 adet parantez olmazsa numpy array şeklinde gözüküyor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales\n",
       "0   22.1\n",
       "1   10.4\n",
       "2    9.3\n",
       "3   18.5\n",
       "4   12.9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head() #Bağımlı değişken(pd df şeklinde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper\n",
       "0  230.1   37.8       69.2\n",
       "1   44.5   39.3       45.1\n",
       "2   17.2   45.9       69.3\n",
       "3  151.5   41.3       58.5\n",
       "4  180.8   10.8       58.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head() #Bağımsız değişkenler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels ile model kurmak\n",
    "# Statsmodel ile, daha fazla bilgi alabileceğimiz doğrusal modellerin yapısına uygun bazı sonuçlar elde edicez. Daha sonra sckit learn ile\n",
    "# sadece katsayılar ile ilgilendiğimiz uygulama yapmış olucaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sm.OLS(y, X) \n",
    "# lm(LinearModel kısaltımını kullandık), ols yani reg modelini kurmak için gerekli olan fonk çağırıyoruz. Burada,\n",
    "# 1.argümana bağımlı değişkeni, ikinci argümana bağımsız değişkenleri yazıyoruz. bu şekilde model nesnesini oluşturalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.fit() \n",
    "# fit işlemi yani modeli kurma işlemi yapalım. lm model nesnesini fit et dedik. yukarıda y,x girdiğimizden, burada girmemize\n",
    "# gerek yok eğer üstte girmeseydik burada girecektik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>sales</td>      <th>  R-squared (uncentered):</th>      <td>   0.982</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.982</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   3566.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 31 Mar 2021</td> <th>  Prob (F-statistic):</th>          <td>2.43e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:58:48</td>     <th>  Log-Likelihood:    </th>          <td> -423.54</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th>          <td>   853.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   197</td>      <th>  BIC:               </th>          <td>   863.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>        <td>    0.0538</td> <td>    0.001</td> <td>   40.507</td> <td> 0.000</td> <td>    0.051</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>radio</th>     <td>    0.2222</td> <td>    0.009</td> <td>   23.595</td> <td> 0.000</td> <td>    0.204</td> <td>    0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>newspaper</th> <td>    0.0168</td> <td>    0.007</td> <td>    2.517</td> <td> 0.013</td> <td>    0.004</td> <td>    0.030</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.982</td> <th>  Durbin-Watson:     </th> <td>   2.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.050</td> <th>  Jarque-Bera (JB):  </th> <td>   7.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.232</td> <th>  Prob(JB):          </th> <td>  0.0296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.794</td> <th>  Cond. No.          </th> <td>    12.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                  sales   R-squared (uncentered):                   0.982\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.982\n",
       "Method:                 Least Squares   F-statistic:                              3566.\n",
       "Date:                Wed, 31 Mar 2021   Prob (F-statistic):                   2.43e-171\n",
       "Time:                        12:58:48   Log-Likelihood:                         -423.54\n",
       "No. Observations:                 200   AIC:                                      853.1\n",
       "Df Residuals:                     197   BIC:                                      863.0\n",
       "Df Model:                           3                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "TV             0.0538      0.001     40.507      0.000       0.051       0.056\n",
       "radio          0.2222      0.009     23.595      0.000       0.204       0.241\n",
       "newspaper      0.0168      0.007      2.517      0.013       0.004       0.030\n",
       "==============================================================================\n",
       "Omnibus:                        5.982   Durbin-Watson:                   2.038\n",
       "Prob(Omnibus):                  0.050   Jarque-Bera (JB):                7.039\n",
       "Skew:                          -0.232   Prob(JB):                       0.0296\n",
       "Kurtosis:                       3.794   Cond. No.                         12.6\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary() #modelin özetleri. Çoklu doğrusal regresyonun model çıktısıdır. Birçok değerli bilgi sunmaktadır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada önemli değerlerden birisi r^2 değeri. R^2 değeri: bağımsız değişkenlerin, bağımlı değişkendeki değişikliğin açıklama yüzdesidir. Verisetimizdeki bağımsız değişkenlerin, sales bağımlı değişkenini açıklama yüzdesi 0,98. Yani oldukça yüksek bir oran. Demekki satışlardaki değişimi açıklamak için çok iyi 3 tane değişkenimiz var demek. \n",
    "Bunun altında düzeltilmiş R^2 değeri isimli başka bir istatistik var. Bu da şu anlama geliyor: R^2 değerinin düzeltilmiş halidir. Yani, R^2 değeri, formulasyonu itibariyle, verisetine ne kadar değişken eklenirse eklensin, şişmeye meyillidir. Yani artmaya meyilllidir. Bu durum, modelde ilgili ya da ilgisiz birçok değişken bulundurma eğilimine sebep olmaktadır. Yani bir veri bilimci, bir model geliştirici, model geliştirme esnasında, verisetine yeni değişkenler eklediğinde, ve R^2 değerinde bir artma gözlemlediğinde, bu artmanın gerçekten açıklanabilirliğe katkı sağladığını düşünmektedir. Kİ BU YANILTICIDIR. Çünkü, R^2 istatistiği, formülasyonundan dolayı, ne kadar değişken eklenirse o kdar şişmektedir. İşte bu şişmenin önüne, bir düzeltme işlemi gerçekleştirilerek düzeltilmiş R^2 değeri oluşturulmuştur. Vw bu değer bize daha sağlıklı bir açıklanabilirlik oranı vermektedir.  \n",
    "Bir diğer istatistik, F-İstatistiği. F-istatistiği, modelin anlamlılığını test etmek için kullanılan istatistiktik. F-İstatistiğine ilişkin altında p value değeri, burada prob olarak ifade edilmiş, yine 0,05ten oldukça küçük bir değer ve bu modelin anlamlı olduğu bilgisini bize veriyor. Bir model kurduk ama bu model anlamlı mı istatistiki olarak? statsmodel aracılığıyla şu an istatistiki olarak bir doğrusal reg modelini ele alıyoruz ve bu istatistik bize modelin anlamlı oluğ olmadığı bilgisini bize veriyor. 0,05ten küçük bir değer olduğundan dolayı model anlamlıdır diyoruz.\n",
    "\n",
    "Aşağıdaki tabloyla ilgili yorumlama yapalım. Bu tablo verisetindeki değişkenlere ilişkin bazı bilgiler sunuyor. Buradaki coef ifadesi, kurulacak olan nihai modeldeki, bu bağımsız değişkenlerin katsayılarını ifade ediyor.b1,b2,b3 katsayıları yani mesela tvnin katsayısı 0.05. Standart hata, bu katsayıların standart hatasıdır. Elimizde bir katsayı var ama bu katsayı anlamlı mı diye sormuş olduğumuzda, t istatistiği ile ve p value değeri(prob. ile gösterilmiş yani probability olasılık) ile inceleyeceğiz. Burası (p değeri) incelenecek olursa, modellemek için kullanmış olduğumuz bütün değişkenler anlamlıdır. \n",
    "\n",
    "Sckit learnde böyle yorumlama yapma imkanımız yoktur. Bu yorumlamalar çok değerlidir. BUNA ÇOK DİKKAT ET İŞ GÖRÜŞMELERİ İÇİN.\n",
    "\n",
    " Katsayıları yorumlayalım. \n",
    "-tv coef katsayısının yorumu şudur: diğer değişkenler sabit varsayıldığında tv harcamalarında meydana gelebilecek 1 birimlik artış, bağımlı değişkenimiz-sales değişkeninde ortalama 0.05 birim artışa sebep olacaktır. Katsayıların yani değişkenlerin, bağımlı değişkenimizi nasıl etkilediğiyle ilgili bir yorum yapıyoruz. TV harcamalarında 1 birim harcama-yatırım yaparsam, bu satışlarda ortalama 0.05 birimlik artışa sebep olabilecektir.\n",
    "\n",
    "-radyo harcamalarında 1 birimlik değişiklik olduğunda, 1 birimlik artıl olduğunda, satışlar da ortalama 0.22 değişiklik olmasını bekleriz.\n",
    "\n",
    "TEMEL YORUMLAMALAR BUNLAR.\n",
    "\n",
    "Özet:\n",
    "-Modelimiz anlamlı(Prob/f-ist). değişkenlerimizin hepsi anlamlı(p>t). Kullandığımız bağımsız değişkenler, bağımlı değişkenin %98ini çaıklıyor ki bu oran çok çok iyi(adj. r^2).\n",
    "\n",
    "Model kurma işlemini statsmodel aracılığıyla gerçekleştirmiş olduk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##scikit learn ile model kurmak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm  = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.fit(X, y) # Fit et, regresyon modeli kur dedik. Bağımsız değişkeni ve bağımlı değişkeni giriyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.93888937])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_ #Sabitimiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04576465,  0.18853002, -0.00103749]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_ # Bağımsız değişkenlerimize ilişkin katsayı değerleri. 3 değişkenimiz vardı, 3 katsayı geldi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu katsayılar statsmodelde bulduğumuzdan farklı. nedeni Arka tarafta, gerekli ilgili kütüphanelerin kullanmış olduğu \n",
    "# parametre tahmin yöntemleri. Bu ileri bir seviye. Biz genelde sckitlearn kullanacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sales = 2.94 + TV * 0.04 + radio * 0.19 - newspaper * 0.001**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tahmin Fonksiyonumuz bu. Matematiksel bir fonk. Değişken değerlerini girdiğimizde, satışların ne olacağını tahmin etmeye çalışıyoruz. Bize buradaki katsayıları veren nedir? Algoritmadır. Doğrusal regresyon modelidir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30 birim TV, 10 birim radio, 40 birim gazete "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.999999999999999"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.94 + 30 * 0.04 + 10 * 0.19 - 40 * 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeni_veri = [[300],[120],[400]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "yeni_veri = pd.DataFrame(yeni_veri).T #Bunu df e çevirmemiz gerekiyor çok değişkenimiz olduğu için. Transpozu aldık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>120</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  300  120  400"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yeni_veri # şu anda burada bağımsız değişkenin değerlerini görüyoruz. 0=tv,1=radio,2=gazete gibi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38.87688782]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(yeni_veri) #Model nesnesi ile tahmin yapıcaz. Parantez içi bağımsız değişken verileri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada ne yaptık? Biz bağımlı değişken-satış ve bağımsız değişkenler arasındaki ilişkiyi modelledik. Bu ilişkinin patternini, yapısını, nasıl ortaya çıktığını doğrusal fonksiyonel bir formülle ortaya koymuş olduk. Dolayısıyla bu fonksiyon, x'lere bağlı olarak dğişiyor. Bağımsız değişken değerlerine bağlı olarak değişiyor. Bağımsız değişken değerleri ne olursa olsun bunlara verisetinin içinden uygulanmış olan yöntem ile bulunmuş katsayılar uygulandığında sonuçlar hesaplanmış olacak. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "# Başarısını değerlendirelim. Basit doğrusal regresyonda el ile yapmıştık. Şimdi bunu\n",
    "# fonksiyonel yapılar ile hesaplayacağız. Burada MSE yani hata kareler ortalamasını uygulayacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales\n",
       "0   22.1\n",
       "1   10.4\n",
       "2    9.3\n",
       "3   18.5\n",
       "4   12.9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head() #Bunlar y'nin gerçek değerleri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20.52397441],\n",
       "       [12.33785482],\n",
       "       [12.30767078],\n",
       "       [17.59782951],\n",
       "       [13.18867186],\n",
       "       [12.47834763],\n",
       "       [11.72975995],\n",
       "       [12.12295317],\n",
       "       [ 3.72734086],\n",
       "       [12.55084872]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)[0:10] #Modeli kullanarak bağımsız değişken değerlerini yerine girerek tahmin ettiğmiz yŞapka değerleri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.784126314510936"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE = mean_squared_error(y, model.predict(X)) #Soldaki y gerçek değerler, sağdaki y tahmin edilenler.\n",
    "MSE #Birim başı yapılacak ortalama hatamız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6685701407225697"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "RMSE = np.sqrt(MSE) #Hata kareler ortalamasının karekökü.\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Tuning (Model Doğrulama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aslında, diğer bütün makine öğrenmesi algoritmaları için model tuning basamakları ele alınacak. Hiperparametre optimizasyonları gerçekleştirilecek. Çoklu doğrusal reg modelinde bir hiperparametre olmadığından dolayı burada model tuning işleminden ziyade bir model doğrulama işlemi gerçekleştireceğiz. Konu bütünüğü açısından model tuning başlığı altında inceliyoruz. Ama burada yapacağımız şey model doğrulama.\n",
    "Model doğrulama neyid? Sınama seti yaklaşımı ve K-Katlı çapraz doğrulama yaklaşımlarını görmüşdük. İşte bu yaklaşımları burada verisetimizi test-train olarak ayırıp, bunların üzerinden bir model doğrulama işlemini gerçekleştirmiş olucaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper\n",
       "0  230.1   37.8       69.2\n",
       "1   44.5   39.3       45.1\n",
       "2   17.2   45.9       69.3\n",
       "3  151.5   41.3       58.5\n",
       "4  180.8   10.8       58.4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales\n",
       "0   22.1\n",
       "1   10.4\n",
       "2    9.3\n",
       "3   18.5\n",
       "4   12.9"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sinama seti\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 1)\n",
    "# Burada x ve y yi train ve test işlemine tabi tutucaz. Fonsiyonda 1.argümanda x 2. argümanda y yazıyoruz. Test size, kaça kaç bölünecek\n",
    "# Onu belirtiyoruz. Random state her çalıştığında farklı sonuç gelmesin diye yazılıyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>13.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>25.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>90.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>18.7</td>\n",
       "      <td>12.1</td>\n",
       "      <td>23.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>204.1</td>\n",
       "      <td>32.9</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>7.3</td>\n",
       "      <td>28.1</td>\n",
       "      <td>41.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  radio  newspaper\n",
       "108   13.1    0.4       25.6\n",
       "107   90.4    0.3       23.2\n",
       "189   18.7   12.1       23.4\n",
       "14   204.1   32.9       46.0\n",
       "56     7.3   28.1       41.4"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head() #Şu anda verisetini test ve train olarak ikiye ayırdık. Train seti içerisinde bağımsız ve bağımlı değişkenler olacak,\n",
    "# test seti içerisinde bağımlı ve bağımsız değişkenler olacak. İkisinde de. Burada train setinin bağımsız değişkenlerini görüyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sales\n",
       "108    5.3\n",
       "107    8.7\n",
       "189    6.7\n",
       "14    19.0\n",
       "56     5.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head() #Train setinin bağımlı değişkeni de bu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>210.8</td>\n",
       "      <td>49.6</td>\n",
       "      <td>37.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>202.5</td>\n",
       "      <td>22.3</td>\n",
       "      <td>31.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>95.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>280.2</td>\n",
       "      <td>10.1</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>253.8</td>\n",
       "      <td>21.3</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TV  radio  newspaper\n",
       "58   210.8   49.6       37.7\n",
       "40   202.5   22.3       31.6\n",
       "34    95.7    1.4        7.4\n",
       "102  280.2   10.1       21.4\n",
       "184  253.8   21.3       30.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head() # Test setinin bağımsız değişkenleri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sales\n",
       "58    23.8\n",
       "40    16.6\n",
       "34     9.5\n",
       "102   14.8\n",
       "184   17.6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head() # Test setinin bağımlı değişkeni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train ile modelimizi fit edicez. Test ile de test edeceğiz. train_test_split fonksiyonu ile verisetimizi train test olarak ayrdık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "model = lm.fit(X_train, y_train) #Traindeki bağımsız ve bağımlı değişkenini yazdık. Train için modelliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7369025901470923"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# egitim hatasi\n",
    "np.sqrt(mean_squared_error(y_train, model.predict(X_train)))\n",
    "# gerçek değerler ve tahmin edilen değerleri girmemiz gerekiyor. model predict ile tahmin değerlerini buluyoruz. X_train yazdık. Neden?\n",
    "# Çünkü train seti içerisindeki bağımsız değişkenin değerlerini kullanarak bir tahminde bulunucaz. Bu bulduğumuz tahminleri yine train\n",
    "# içerisindeki y'nin gerçek değerleri ile karşılaştırıcam.\n",
    "# Burada bulduğumuz hata, train hatamız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4113417558581578"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test hatasi\n",
    "np.sqrt(mean_squared_error(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Özetle, Verisetimizi train ve test olarak ikiye böldük. Train üzerinde bir model kurduk. Ve kurmuş olduğumuz modelimize ilişkin hatamızı hesapladık. Daha sonra ayırmış olduğumuz test setini de göz önünde bulundurarak, test seti için de bir hata hesapladık. Bu sınama seti yaklaşımıyla hata hesaplama işlemiydi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yukarıdaki random state'i değiştirirsek, bu hata değerlerimiz de değişecektir. Nedeni, verisetinin içerisindeki hangi 80/20'yi alacağız. Bunlar değiştiği için hatalar da değişmekte. Bir rastegele işlemde farklı 80/20, başka bir rastgele işlemde farklı 80/20 alınabilir. Bu da sonuçları yanıltıcı olarak değerlendirmemize sebep olabilir. İşte bu sebeple, K-Katlı CV kullanıyoruz. Train setine yönelik elde edecek olduğumuz hatayı daha doğru değerlendirebilemk adına K-Katlı CV yöntemini kullanmış olucaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-katlı cv(cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.62375953, -3.81875608, -3.43828142, -2.27748673, -7.25325414,\n",
       "       -1.88303708, -2.80517715, -3.68594486, -1.12810834, -3.96330989])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(model, X_train, y_train, cv = 10, scoring = \"neg_mean_squared_error\")\n",
    "#1.argümana modeli yazıyoruz. 2.argüman bağımsız değişkenleri ifade ediyor.daha sonra bağımlı değişkenimizi ifade ediyoruz. cv kaç katlı\n",
    "# olsun diyor. 10 katlı olsun dedik. scoring argümanı ise, hata kareler ortalaması diye dolduruyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ne oldu? Train seti üzerinden 10 tane farklı hata hesaplandı. Yani train seti kendi içinde 10 parçaya bölündü, 9 parça ile önce model kurulup, dışarıda kalan 1 parça tahmin edildi. Bir hata elde edildi. sonra diğer parça dışarıda bırakılıp, 9 parça ile model kurulup, dışarıda bırakılan parça tahmin edilmeye çalışıldı. Ve bu şekilde 10 tane hata elde edildi. Bunu trainin üzerinde yapıyoruz. Netice itibariyle bunların ortalamasını aldığımızda, elimizde tek bir tane traine ilişkin hata olacak. Fakat buradaki değerler negatif. Bu fonksiyonun kullanımıyla ilgili bir durum. Başına bir eksi işareti koyup ortalamasını al dediğimizde, ortalama hata gelmiş olacak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.187711520944358"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv mse\n",
    "np.mean(-cross_val_score(model, X_train, y_train, cv = 10, scoring = \"neg_mean_squared_error\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yani train setimize ilişkin ortalama hatamız bu. Bunun karekökünğ alırsak, RMSE değerine erişmiş oluruz. Tabi bu sadece train seti üzerinde bir işlemdi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7854163438661466"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv rmse\n",
    "np.sqrt(np.mean(-cross_val_score(model, X_train, y_train, cv = 10, scoring = \"neg_mean_squared_error\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eğer CV yöntemi ile sınama seti yöntemini karşılaştırmak ana amacımız ise, bu durumda sadece x ve y yazarsak bu işlemi de gerçekleştirecektir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7492763126843378"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv rmse\n",
    "np.sqrt(np.mean(-cross_val_score(model, X, y, cv = 10, scoring = \"neg_mean_squared_error\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ama burada tüm veriyi tek bir veri olarak kabul etti. Teorik bölümde gördüğümüz, genelde bazı kafa karışıklıklarına sebep olan kısım burası. Tavsiye: çalışmanın başında eğer veriseti kümeniz yeteri kadar büyük ise, en son nihai testleri yapmak üzere bir test setini dışarıda bırakmanız, dışarıda ırakılan bu test setini daha sonra en son modeli oluşturduğunuzda tet etmeniz. Yani CV işlemini train setini sanki tek bir veri gibi kabul edip, bunun üzerinde gerçekleştirmeniz. Tıpkı iki satır üstte yaptığımız gibi. Test seti her zaman dışarıda kalmalı. O test seti dışarıda iken (tabi eğer veriseti yeteri kadar büyük ise) elimizdeki train setini ikiye bölüp, sanki test ve train buradaymışçasına hareket edip, ki bunu çapraz doğrulama ile validayon yöntemine yaptırıp, yani biz burada şu anda crosvalscore fonksiyonunu çalıştırdığımızda buraya girmiş olduğumuz x_train ve y_train sanki tek bir veriymiş gibi kabul ediliyo, bu kendi içinde 10 katlı işlemi periyodik olarak hepsine yapılıyor. Yani kendi içinde 10 tane parçaya bölüyor bunu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PEKİ BU DEĞER NE DEMEK? biz bu işlemi neden yaptık? Daha önce basitçe bir test hatası eğitim hatası işlemi yapmıştık. Neden böyle bir işleme gerek duyduk? Bu işlem bize, sadece tek başına test ve trainin vermiş olduğu hatadan daha doğru bir hata ölçüsü verir. Yani DOĞRULANMIŞTIR. Modeli doğrulamak demek, bu demektir. Verisetinin içerisinden seçilebilecek farklı varyasyonlara ilişkin bir hata hesaplaması yapılır. Bir defa değil mesela burada 10 defa yapılır. Dolayısıyla hepsinin ortalaması alındığında bize ilkel yöntem diyebileceğimiz, ilkel test hatasıi ilkel train hatası diyebileceğimiz hatalara göre valide edilmiş hatayı verir. CV, doğrulanmış bir hata verir. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regresyon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerekli Kütüphaneler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veri Seti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hitters.csv\") #Veriyi okuduk.\n",
    "\n",
    "df = df.dropna() #İçindeki eksik değerleri direkt sildik.\n",
    "\n",
    "dms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])#Kategorik değişkenleri, dummy değişkene çevirdik.\n",
    "#KAtegorik değişkenlerin bize sağlacak olduğu bilgiyi daha iyi alabilmek adına one hot encoding yaklaşımı yapmış olduk.\n",
    "\n",
    "y = df[\"Salary\"] #Bağımlı değişkenimiz salary\n",
    "\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64') #Bağımsız değişkenleri oluşturmadan önce, dummy sonrası\n",
    "#değişkenlerin kendileri var burada, bunlar kategorik değişkenler. Bunları ve bağımşı değişkeni verietinden çıkartıyoruz.\n",
    "\n",
    "X = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1) #Daha sonra original veriseti ile bu yukarıdakini birleştirdik.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)#test-train ayrımı yaptık.75/25 şeklinde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  CRuns  \\\n",
       "1    315    81      7    24   38     39     14    3449    835      69    321   \n",
       "2    479   130     18    66   72     76      3    1624    457      63    224   \n",
       "3    496   141     20    65   78     37     11    5628   1575     225    828   \n",
       "4    321    87     10    39   42     30      2     396    101      12     48   \n",
       "5    594   169      4    74   51     35     11    4408   1133      19    501   \n",
       "\n",
       "   CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary NewLeague  \n",
       "1   414     375      N        W      632       43      10   475.0         N  \n",
       "2   266     263      A        W      880       82      14   480.0         A  \n",
       "3   838     354      N        E      200       11       3   500.0         N  \n",
       "4    46      33      N        E      805       40       4    91.5         N  \n",
       "5   336     194      A        W      282      421      25   750.0         A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amacımız: salary(oyuncuların maaşı) değişkenini, diğer değişkenleri kullanarak tahmin etmeye çalışmak. \n",
    "Verisetinin hikayesi: beyzbol oyuncularına ait veriseti. Bu verisetinin içinde oyunculara ilişkin maaşları, oynadıkları lig, attıkları sayı, koşuları vb. bir takım bilgiler var. Burada bizim için önemli olan maaş değişkeni. Başka senaryoda hits isimli değişken de önemli olabilir vs.vs.\n",
    "Problemimiz: Kulüp başkanı diyor ki, ben bir oyuncu transfer etmek istiyorum. Ama oyuncuya ne kadar bedel belirtmem gerektiğini bilmiyorum. Elimde geçmiş veriler var. Geçmiş verilere bakarak bana öyle bir değer söyle ki, bu kişiye ona göre bir maaş vermek adına bir yorumlama yapabileyim.\n",
    "Aynı zamanda bu çalışma aracılığıyla, Yüksek potanasiyel ifade eden pyuncular tespit de edilebilir. Mesela, maaşı çok yüksek olması gerektiği halde, mevcut maaşı düşük olan oyuncular transfer listesine eklenebilir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aslında, bu verinin görselleştirilmesi betimsel istatistiklerine bakılması, birbirleri ile çaprazlanarak verisetinin daha yakından tanınmaya çalışılması gibi bir dizi işlemin de gerçekleştirilmesi gerekiyor. Fakat buradaki çalışma kapsamında, veri ön işlemeye ya da veri manipülasyonuna, keşifçi veri analizine ilişkin işlemleri gözardı ederek devam edeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha = 5).fit(X_train, y_train) #Ridgemodelimizi nesnesi oluşturduk. train seti üzerinden fit ediyoruz. eğitiyoruz.\n",
    "# alpha parametresini biz giriyoruz. Yani lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.81040449,   8.87872786,   7.12487047,  -3.31713488,\n",
       "        -2.01162162,   5.40691525,   7.25828404,  -0.13033385,\n",
       "        -0.25425913,  -0.71109275,   1.81452   ,   0.77083457,\n",
       "        -0.6768975 ,   0.26211894,   0.2646614 ,  -0.36947934,\n",
       "        76.19519054, -90.15523668, -16.00453535])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.coef_ #katsayılar. Farklı lambda değerlerine karşılık, farklı katsayılar oluşacak ve her farklı lamda değeriyle oluşan katsayılar\n",
    "#üzerinden kurulan modeller ve bunların neticesinde ortaya çıkan hatalar incelenecek. Buna göre optimum alphaya yani lambdaya karar verilecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.425196868715034"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.intercept_ #sabit katsayımız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.        ,  9.87878788,  9.75757576,  9.63636364,  9.51515152,\n",
       "        9.39393939,  9.27272727,  9.15151515,  9.03030303,  8.90909091,\n",
       "        8.78787879,  8.66666667,  8.54545455,  8.42424242,  8.3030303 ,\n",
       "        8.18181818,  8.06060606,  7.93939394,  7.81818182,  7.6969697 ,\n",
       "        7.57575758,  7.45454545,  7.33333333,  7.21212121,  7.09090909,\n",
       "        6.96969697,  6.84848485,  6.72727273,  6.60606061,  6.48484848,\n",
       "        6.36363636,  6.24242424,  6.12121212,  6.        ,  5.87878788,\n",
       "        5.75757576,  5.63636364,  5.51515152,  5.39393939,  5.27272727,\n",
       "        5.15151515,  5.03030303,  4.90909091,  4.78787879,  4.66666667,\n",
       "        4.54545455,  4.42424242,  4.3030303 ,  4.18181818,  4.06060606,\n",
       "        3.93939394,  3.81818182,  3.6969697 ,  3.57575758,  3.45454545,\n",
       "        3.33333333,  3.21212121,  3.09090909,  2.96969697,  2.84848485,\n",
       "        2.72727273,  2.60606061,  2.48484848,  2.36363636,  2.24242424,\n",
       "        2.12121212,  2.        ,  1.87878788,  1.75757576,  1.63636364,\n",
       "        1.51515152,  1.39393939,  1.27272727,  1.15151515,  1.03030303,\n",
       "        0.90909091,  0.78787879,  0.66666667,  0.54545455,  0.42424242,\n",
       "        0.3030303 ,  0.18181818,  0.06060606, -0.06060606, -0.18181818,\n",
       "       -0.3030303 , -0.42424242, -0.54545455, -0.66666667, -0.78787879,\n",
       "       -0.90909091, -1.03030303, -1.15151515, -1.27272727, -1.39393939,\n",
       "       -1.51515152, -1.63636364, -1.75757576, -1.87878788, -2.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(10,-2,100) #Bu ne demekti? 10/-2 arasında 100 tane değer ver demek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdalar = 10**np.linspace(10,-2,100)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.00000000e+09, 3.78231664e+09, 2.86118383e+09, 2.16438064e+09,\n",
       "       1.63727458e+09, 1.23853818e+09, 9.36908711e+08, 7.08737081e+08,\n",
       "       5.36133611e+08, 4.05565415e+08, 3.06795364e+08, 2.32079442e+08,\n",
       "       1.75559587e+08, 1.32804389e+08, 1.00461650e+08, 7.59955541e+07,\n",
       "       5.74878498e+07, 4.34874501e+07, 3.28966612e+07, 2.48851178e+07,\n",
       "       1.88246790e+07, 1.42401793e+07, 1.07721735e+07, 8.14875417e+06,\n",
       "       6.16423370e+06, 4.66301673e+06, 3.52740116e+06, 2.66834962e+06,\n",
       "       2.01850863e+06, 1.52692775e+06, 1.15506485e+06, 8.73764200e+05,\n",
       "       6.60970574e+05, 5.00000000e+05, 3.78231664e+05, 2.86118383e+05,\n",
       "       2.16438064e+05, 1.63727458e+05, 1.23853818e+05, 9.36908711e+04,\n",
       "       7.08737081e+04, 5.36133611e+04, 4.05565415e+04, 3.06795364e+04,\n",
       "       2.32079442e+04, 1.75559587e+04, 1.32804389e+04, 1.00461650e+04,\n",
       "       7.59955541e+03, 5.74878498e+03, 4.34874501e+03, 3.28966612e+03,\n",
       "       2.48851178e+03, 1.88246790e+03, 1.42401793e+03, 1.07721735e+03,\n",
       "       8.14875417e+02, 6.16423370e+02, 4.66301673e+02, 3.52740116e+02,\n",
       "       2.66834962e+02, 2.01850863e+02, 1.52692775e+02, 1.15506485e+02,\n",
       "       8.73764200e+01, 6.60970574e+01, 5.00000000e+01, 3.78231664e+01,\n",
       "       2.86118383e+01, 2.16438064e+01, 1.63727458e+01, 1.23853818e+01,\n",
       "       9.36908711e+00, 7.08737081e+00, 5.36133611e+00, 4.05565415e+00,\n",
       "       3.06795364e+00, 2.32079442e+00, 1.75559587e+00, 1.32804389e+00,\n",
       "       1.00461650e+00, 7.59955541e-01, 5.74878498e-01, 4.34874501e-01,\n",
       "       3.28966612e-01, 2.48851178e-01, 1.88246790e-01, 1.42401793e-01,\n",
       "       1.07721735e-01, 8.14875417e-02, 6.16423370e-02, 4.66301673e-02,\n",
       "       3.52740116e-02, 2.66834962e-02, 2.01850863e-02, 1.52692775e-02,\n",
       "       1.15506485e-02, 8.73764200e-03, 6.60970574e-03, 5.00000000e-03])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdalar #birbirinden farklı birçok lambda elde ettik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi amacımız şu: bu oluşturduğumuz lambda değerlerine karşı katsayıların nasıl değişecek olduğunu gözlemlemeye çalışmak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge() #ridge model isminde ridge nesnesi oluşturduk\n",
    "katsayilar = [] # daha sonrakatsayılar isminde boş bir liste oluşturduk.\n",
    "\n",
    "# şimdi döngü aracılığıyla ortaya çıkan bu durumu gözlemlemiş olucaz.\n",
    "\n",
    "for i in lambdalar:\n",
    "    ridge_model.set_params(alpha = i) #paramaetreleri set etme işlemi. i ye göre alphayı değiştirecek.\n",
    "    ridge_model.fit(X_train, y_train) #artık i ye göre parametre ayarlandı. şimdi fit ediyoruz.\n",
    "    katsayilar.append(ridge_model.coef_) #çıkan her bir alpha değerine karşılık gelecek şekilde oluşturulan modellerin katsayılarını listeye ekliyoruz.\n",
    "    \n",
    "# DİKKAT: Her lambda denemesinde bir çok katsayı olacak. Her lambdanın 19 tane(bağımsız değişken sayısı kadar) katsayısı olacak. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.08705828e-03,  3.59972026e-04,  5.52181027e-05,  1.92813177e-04,\n",
       "         1.96696069e-04,  1.59478501e-04,  2.78199599e-05,  1.78978518e-02,\n",
       "         5.28448603e-03,  6.33684784e-04,  2.78574434e-03,  2.70578331e-03,\n",
       "         1.95710128e-03,  1.87423190e-03,  1.54040667e-04,  2.97933111e-06,\n",
       "         2.39984989e-07, -1.51804510e-06,  3.31089982e-07]),\n",
       " array([ 1.41677983e-03,  4.69820454e-04,  7.18242293e-05,  2.52218183e-04,\n",
       "         2.55763476e-04,  2.07728851e-04,  3.41731833e-05,  2.22675231e-02,\n",
       "         6.58971645e-03,  7.96723486e-04,  3.48283639e-03,  3.38849662e-03,\n",
       "         2.44474193e-03,  2.46055074e-03,  2.00411447e-04,  4.05879985e-06,\n",
       "         3.06791363e-07, -2.00697735e-06,  4.22750663e-07]),\n",
       " array([ 1.84180994e-03,  6.11797854e-04,  9.31516430e-05,  3.29313865e-04,\n",
       "         3.31574150e-04,  2.69862282e-04,  4.11993224e-05,  2.73092348e-02,\n",
       "         8.10613246e-03,  9.90615632e-04,  4.29892819e-03,  4.19154557e-03,\n",
       "         3.01420413e-03,  3.22598807e-03,  2.59998767e-04,  5.54696646e-06,\n",
       "         3.89590845e-07, -2.65335139e-06,  5.35999686e-07]),\n",
       " array([ 2.38835573e-03,  7.94911180e-04,  1.20464748e-04,  4.29197870e-04,\n",
       "         4.28587877e-04,  3.49672945e-04,  4.85735865e-05,  3.29487297e-02,\n",
       "         9.81901671e-03,  1.21671761e-03,  5.23061273e-03,  5.11427511e-03,\n",
       "         3.66208312e-03,  4.22364586e-03,  3.36365620e-04,  7.59686227e-06,\n",
       "         4.91353840e-07, -3.50777634e-06,  6.74604224e-07]),\n",
       " array([ 3.09009626e-03,  1.03077807e-03,  1.55382775e-04,  5.58473604e-04,\n",
       "         5.52508877e-04,  4.52038103e-04,  5.57795062e-05,  3.90401495e-02,\n",
       "         1.16953022e-02,  1.47539158e-03,  6.26651564e-03,  6.14928402e-03,\n",
       "         4.37897884e-03,  5.52205602e-03,  4.34090225e-04,  1.04109479e-05,\n",
       "         6.15653427e-07, -4.63702970e-06,  8.42961127e-07]),\n",
       " array([ 3.99078636e-03,  1.33452564e-03,  2.00008537e-04,  7.25754223e-04,\n",
       "         7.10738029e-04,  5.83304802e-04,  6.21041602e-05,  4.53725039e-02,\n",
       "         1.36860237e-02,  1.76653067e-03,  7.38894131e-03,  7.28417751e-03,\n",
       "         5.15056825e-03,  7.20959605e-03,  5.59142468e-04,  1.42511133e-05,\n",
       "         7.67085867e-07, -6.12914603e-06,  1.04655631e-06]),\n",
       " array([ 5.14774210e-03,  1.72599105e-03,  2.57103265e-04,  9.42329790e-04,\n",
       "         9.12986699e-04,  7.51813035e-04,  6.66592521e-05,  5.16922252e-02,\n",
       "         1.57335162e-02,  2.09064895e-03,  8.57804087e-03,  8.50573034e-03,\n",
       "         5.96044306e-03,  9.39987293e-03,  7.19400260e-04,  1.94483594e-05,\n",
       "         9.51936629e-07, -8.10006447e-06,  1.29268236e-06]),\n",
       " array([ 6.63625037e-03,  2.23124851e-03,  3.30309746e-04,  1.22301529e-03,\n",
       "         1.17205779e-03,  9.68565766e-04,  6.84187693e-05,  5.77371815e-02,\n",
       "         1.77820817e-02,  2.45041949e-03,  9.81789688e-03,  9.80588055e-03,\n",
       "         6.79427058e-03,  1.22378921e-02,  9.25318808e-04,  2.64114755e-05,\n",
       "         1.17910270e-06, -1.07022908e-05,  1.59137023e-06]),\n",
       " array([ 8.55483745e-03,  2.88445935e-03,  4.24420527e-04,  1.58718502e-03,\n",
       "         1.50477879e-03,  1.24804330e-03,  6.62540589e-05,  6.32720806e-02,\n",
       "         1.97893052e-02,  2.85238338e-03,  1.11031502e-02,  1.11882336e-02,\n",
       "         7.64428385e-03,  1.59064960e-02,  1.19075375e-03,  3.56332379e-05,\n",
       "         1.46126190e-06, -1.41361477e-05,  1.95642271e-06]),\n",
       " array([ 1.10312454e-02,  3.73002061e-03,  5.45684591e-04,  2.05998878e-03,\n",
       "         1.93305764e-03,  1.60915216e-03,  5.89463545e-05,  6.81144258e-02,\n",
       "         2.17349754e-02,  3.30852528e-03,  1.24446956e-02,  1.26736367e-02,\n",
       "         8.51303131e-03,  2.06320735e-02,  1.53393253e-03,  4.76905218e-05,\n",
       "         1.81630840e-06, -1.86643235e-05,  2.40641302e-06]),\n",
       " array([ 1.42288809e-02,  4.82496917e-03,  7.02143825e-04,  2.67373455e-03,\n",
       "         2.48502252e-03,  2.07629541e-03,  4.51663040e-05,  7.21446369e-02,\n",
       "         2.36258289e-02,  3.83753128e-03,  1.38736179e-02,  1.43039512e-02,\n",
       "         9.41577138e-03,  2.66878486e-02,  1.97856321e-03,  6.32307599e-05,\n",
       "         2.26916665e-06, -2.46305879e-05,  2.96553891e-06]),\n",
       " array([ 1.83533492e-02,  6.24156186e-03,  9.03986475e-04,  3.46940075e-03,\n",
       "         3.19618820e-03,  2.68054308e-03,  2.34244013e-05,  7.53005841e-02,\n",
       "         2.54962052e-02,  4.46571897e-03,  1.54434962e-02,  1.61439894e-02,\n",
       "         1.03815693e-02,  3.43920784e-02,  2.55505046e-03,  8.29312258e-05,\n",
       "         2.85425312e-06, -3.24837353e-05,  3.66428247e-06]),\n",
       " array([ 2.36583931e-02,  8.06987606e-03,  1.16389452e-03,  4.49819833e-03,\n",
       "         4.11055071e-03,  3.46085782e-03, -7.99178240e-06,  7.75617205e-02,\n",
       "         2.74060905e-02,  5.22774181e-03,  1.72319022e-02,  1.82821668e-02,\n",
       "         1.14536429e-02,  4.40972790e-02,  3.30173084e-03,  1.07409746e-04,\n",
       "         3.61908966e-06, -4.28080520e-05,  4.53991031e-06]),\n",
       " array([ 3.04501016e-02,  1.04201578e-02,  1.49734514e-03,  5.82303756e-03,\n",
       "         5.28144612e-03,  4.46529082e-03, -5.10715931e-05,  7.89293976e-02,\n",
       "         2.94384183e-02,  6.16716441e-03,  1.93421004e-02,  2.08305107e-02,\n",
       "         1.26896156e-02,  5.61654836e-02,  4.26591900e-03,  1.37056133e-04,\n",
       "         4.62994572e-06, -5.63619514e-05,  5.63701574e-06]),\n",
       " array([ 3.90877335e-02,  1.34245129e-02,  1.92280724e-03,  7.51967840e-03,\n",
       "         6.77193714e-03,  5.75201908e-03, -1.08103747e-04,  7.94085363e-02,\n",
       "         3.16971295e-02,  7.33690583e-03,  2.19057141e-02,  2.39243876e-02,\n",
       "         1.41621442e-02,  7.09243460e-02,  5.50434864e-03,  1.71744357e-04,\n",
       "         5.98103051e-06, -7.41269482e-05,  7.00870479e-06]),\n",
       " array([ 4.99790908e-02,  1.72374527e-02,  2.46176162e-03,  9.67728453e-03,\n",
       "         8.65444650e-03,  7.39007141e-03, -1.81647005e-04,  7.89933590e-02,\n",
       "         3.43069156e-02,  8.79941161e-03,  2.50867048e-02,  2.77219584e-02,\n",
       "         1.59600508e-02,  8.86010366e-02,  7.08228283e-03,  2.10379504e-04,\n",
       "         7.80986903e-06, -9.73700195e-05,  8.71990580e-06]),\n",
       " array([ 6.35683184e-02,  2.20348389e-02,  3.13847615e-03,  1.23980931e-02,\n",
       "         1.10093810e-02,  9.45961578e-03, -2.74433813e-04,  7.76577086e-02,\n",
       "         3.74152151e-02,  1.06262815e-02,  2.90865964e-02,  3.24031662e-02,\n",
       "         1.81897361e-02,  1.09236939e-01,  9.07018129e-03,  2.50236073e-04,\n",
       "         1.03233178e-05, -1.27723784e-04,  1.08559283e-05]),\n",
       " array([ 8.03144193e-02,  2.80109646e-02,  3.97948810e-03,  1.57959666e-02,\n",
       "         1.39225986e-02,  1.20517651e-02, -3.89198631e-04,  7.53491228e-02,\n",
       "         4.11970425e-02,  1.28969399e-02,  3.41504870e-02,  3.81680540e-02,\n",
       "         2.09762607e-02,  1.32596777e-01,  1.15364715e-02,  2.86060551e-04,\n",
       "         1.38414001e-05, -1.67290929e-04,  1.35420021e-05]),\n",
       " array([ 1.00659415e-01,  3.53737763e-02,  5.01276201e-03,  1.99936664e-02,\n",
       "         1.74817046e-02,  1.52679591e-02, -5.28428627e-04,  7.19852765e-02,\n",
       "         4.58634610e-02,  1.56957180e-02,  4.05729409e-02,  4.52341750e-02,\n",
       "         2.44629669e-02,  1.58098532e-01,  1.45349889e-02,  3.08943729e-04,\n",
       "         1.88697449e-05, -2.18781763e-04,  1.69829249e-05]),\n",
       " array([ 1.24985300e-01,  4.43383743e-02,  6.26646135e-03,  2.51186578e-02,\n",
       "         2.17711724e-02,  1.92189991e-02, -6.94031851e-04,  6.74515998e-02,\n",
       "         5.16745666e-02,  1.91063111e-02,  4.87021870e-02,  5.38323815e-02,\n",
       "         2.88077603e-02,  1.84798490e-01,  1.80865855e-02,  3.05013003e-04,\n",
       "         2.62154267e-05, -2.85696212e-04,  2.15353352e-05]),\n",
       " array([ 1.53558197e-01,  5.51187291e-02,  7.76715884e-03,  3.12970555e-02,\n",
       "         2.68660409e-02,  2.40236617e-02, -8.86898780e-04,  6.15998145e-02,\n",
       "         5.89572171e-02,  2.32019817e-02,  5.89401216e-02,  6.41990135e-02,\n",
       "         3.41732141e-02,  2.11459552e-01,  2.21569148e-02,  2.54044649e-04,\n",
       "         3.71643214e-05, -3.72563522e-04,  2.78270230e-05]),\n",
       " array([ 1.86457341e-01,  6.79172663e-02,  9.53716658e-03,  3.86451070e-02,\n",
       "         3.28235831e-02,  2.98066321e-02, -1.10629915e-03,  5.42486226e-02,\n",
       "         6.81259518e-02,  2.80294254e-02,  7.17346292e-02,  7.65608732e-02,\n",
       "         4.07069956e-02,  2.36706263e-01,  2.66367239e-02,  1.28145040e-04,\n",
       "         5.37390333e-05, -4.85254784e-04,  3.69363946e-05]),\n",
       " array([ 2.23488679e-01,  8.29124771e-02,  1.15906901e-02,  4.72579656e-02,\n",
       "         3.96724511e-02,  3.66957155e-02, -1.34902777e-03,  4.51891944e-02,\n",
       "         7.97025208e-02,  3.35848087e-02,  8.75603655e-02,  9.11090818e-02,\n",
       "         4.85098565e-02,  2.59234910e-01,  3.13359801e-02, -1.09311057e-04,\n",
       "         7.90531634e-05, -6.31387074e-04,  5.06394947e-05]),\n",
       " array([ 2.64091406e-01,  1.00247072e-01,  1.39289695e-02,  5.71971039e-02,\n",
       "         4.74001434e-02,  4.48194982e-02, -1.60821935e-03,  3.41983905e-02,\n",
       "         9.43255889e-02,  3.97832322e-02,  1.06885319e-01,  1.07961438e-01,\n",
       "         5.75920571e-02,  2.78020879e-01,  3.60055069e-02, -5.04310897e-04,\n",
       "         1.17769153e-04, -8.20846578e-04,  7.17218276e-05]),\n",
       " array([ 3.07259930e-01,  1.20023291e-01,  1.65355470e-02,  6.84805408e-02,\n",
       "         5.59422985e-02,  5.43089014e-02, -1.87179996e-03,  2.10611519e-02,\n",
       "         1.12738462e-01,  4.64280598e-02,  1.30123747e-01,  1.27121136e-01,\n",
       "         6.78260905e-02,  2.92464684e-01,  4.03947313e-02, -1.11239332e-03,\n",
       "         1.76654795e-04, -1.06647321e-03,  1.04339598e-04]),\n",
       " array([ 3.51515911e-01,  1.42315715e-01,  1.93739007e-02,  8.10827983e-02,\n",
       "         6.51800228e-02,  6.53084038e-02, -2.12059533e-03,  5.60078488e-03,\n",
       "         1.35740789e-01,  5.31920946e-02,  1.57580614e-01,  1.48449082e-01,\n",
       "         7.89114962e-02,  3.02442388e-01,  4.43389399e-02, -1.99879194e-03,\n",
       "         2.65224510e-04, -1.38496929e-03,  1.54405607e-04]),\n",
       " array([ 3.94963670e-01,  1.67212044e-01,  2.23900744e-02,  9.49519148e-02,\n",
       "         7.49518524e-02,  7.80032771e-02, -2.32611607e-03, -1.22861853e-02,\n",
       "         1.64092518e-01,  5.96238619e-02,  1.89396119e-01,  1.71669244e-01,\n",
       "         9.03706006e-02,  3.08260068e-01,  4.78484595e-02, -3.23949414e-03,\n",
       "         3.96457704e-04, -1.79811559e-03,  2.29979158e-04]),\n",
       " array([ 4.35440787e-01,  1.94886967e-01,  2.55218451e-02,  1.10047299e-01,\n",
       "         8.50833041e-02,  9.26665587e-02, -2.44796656e-03, -3.25937122e-02,\n",
       "         1.98367303e-01,  6.51849964e-02,  2.25498900e-01,  1.96414281e-01,\n",
       "         1.01586618e-01,  3.10538783e-01,  5.11581599e-02, -4.92458797e-03,\n",
       "         5.87619775e-04, -2.33439666e-03,  3.41667593e-04]),\n",
       " array([ 0.4707398 ,  0.22570501,  0.02871347,  0.12639534,  0.09542999,\n",
       "         0.10972413, -0.00243074, -0.05516994,  0.23876852,  0.06931006,\n",
       "         0.26557372,  0.2222951 ,  0.11187863,  0.31006874,  0.05470242,\n",
       "        -0.00716513,  0.00086127, -0.00303116,  0.0005031 ]),\n",
       " array([ 0.49884358,  0.26033979,  0.03193236,  0.14415252,  0.10592353,\n",
       "         0.12983066, -0.00220023, -0.07968271,  0.28494095,  0.07146667,\n",
       "         0.30904807,  0.24895963,  0.12059091,  0.30767017,  0.05901068,\n",
       "        -0.01010398,  0.00124662, -0.00393745,  0.0007316 ]),\n",
       " array([ 0.51810441,  0.29989425,  0.03518278,  0.16366201,  0.11660696,\n",
       "         0.15394607, -0.00165906, -0.10559393,  0.33582833,  0.07119222,\n",
       "         0.35510609,  0.27611091,  0.12716769,  0.30408785,  0.06455753,\n",
       "        -0.01392994,  0.00178144, -0.00511776,  0.00104922]),\n",
       " array([ 0.52731238,  0.34600997,  0.0385126 ,  0.18549005,  0.1276497 ,\n",
       "         0.18340272, -0.00068181, -0.13215709,  0.38963232,  0.06809583,\n",
       "         0.40274434,  0.30348383,  0.13119077,  0.29993061,  0.07162596,\n",
       "        -0.01889366,  0.00251475, -0.0066569 ,  0.00148436]),\n",
       " array([ 0.52563557,  0.40096129,  0.04201125,  0.21043195,  0.13933819,\n",
       "         0.21995563,  0.00088985, -0.15845442,  0.44391197,  0.06183284,\n",
       "         0.45088281,  0.33080995,  0.13237205,  0.2956528 ,  0.08023781,\n",
       "        -0.02532345,  0.00351064, -0.00866639,  0.00207418]),\n",
       " array([ 0.51245689,  0.46773416,  0.04579935,  0.23947869,  0.15204364,\n",
       "         0.26581035,  0.00325215, -0.18347884,  0.49582229,  0.05207147,\n",
       "         0.49852755,  0.35780758,  0.13050722,  0.29156508,  0.09017435,\n",
       "        -0.03363913,  0.00485343, -0.01129272,  0.00286803]),\n",
       " array([ 0.48716485,  0.55008855,  0.05001106,  0.27373331,  0.16616941,\n",
       "         0.32362115,  0.00664439, -0.20624638,  0.54243844,  0.03847238,\n",
       "         0.54495307,  0.38421156,  0.1254093 ,  0.28786002,  0.10106927,\n",
       "        -0.04436196,  0.00665481, -0.01472784,  0.00393228]),\n",
       " array([ 0.4489693 ,  0.65259294,  0.0547705 ,  0.31425899,  0.18207896,\n",
       "         0.39644748,  0.01135508, -0.22590778,  0.58107838,  0.02069636,\n",
       "         0.58985146,  0.40982593,  0.11684682,  0.28464147,  0.11252912,\n",
       "        -0.05811777,  0.00906349, -0.01922258,  0.00535701]),\n",
       " array([ 0.3968063 ,  0.78060342,  0.06016408,  0.36183375,  0.20000384,\n",
       "         0.48764781,  0.01772912, -0.24182798,  0.60954426, -0.00155238,\n",
       "         0.63339787,  0.4345655 ,  0.10451029,  0.28195087,  0.12423297,\n",
       "        -0.07562832,  0.01227822, -0.02510361,  0.00726512]),\n",
       " array([ 0.32937467,  0.9401416 ,  0.06621354,  0.41658487,  0.21993467,\n",
       "         0.60068406,  0.02617569, -0.25361874,  0.62624781, -0.02844544,\n",
       "         0.67621095,  0.45845871,  0.0880216 ,  0.27978824,  0.13598169,\n",
       "        -0.09768359,  0.01656543, -0.03279487,  0.00982478]),\n",
       " array([ 0.24531948,  1.13761151,  0.07286178,  0.4774922 ,  0.2415094 ,\n",
       "         0.73881463,  0.03717582, -0.2611302 ,  0.63023671, -0.05991964,\n",
       "         0.71922379,  0.48160498,  0.06698821,  0.27812741,  0.1476926 ,\n",
       "        -0.12508529,  0.02228264, -0.04284536,  0.01326611]),\n",
       " array([ 0.1435482 ,  1.37929734,  0.07999484,  0.54179368,  0.26393219,\n",
       "         0.90467818,  0.05128863, -0.26442052,  0.62116703, -0.0955613 ,\n",
       "         0.76350787,  0.50410208,  0.04109169,  0.27692596,  0.15935413,\n",
       "        -0.15855204,  0.02990935, -0.05596537,  0.0179032 ]),\n",
       " array([ 0.02363255,  1.67061387,  0.08753565,  0.60440494,  0.28597299,\n",
       "         1.09981641,  0.06915608, -0.26372195,  0.59926001, -0.13453482,\n",
       "         0.81009977,  0.52597367,  0.01019011,  0.27613096,  0.17096354,\n",
       "        -0.19858115,  0.04008731, -0.07307487,  0.0241626 ]),\n",
       " array([-0.11378671,  2.01514908,  0.09564972,  0.65756367,  0.30609314,\n",
       "         1.32423652,  0.0915081 , -0.2594123 ,  0.56525502, -0.17562381,\n",
       "         0.85987142,  0.54713291, -0.02559235,  0.27568181,  0.18246959,\n",
       "        -0.2452718 ,  0.05367214, -0.09536904,  0.0326191 ]),\n",
       " array([-0.26670385,  2.41363844,  0.10508862,  0.69098126,  0.32269376,\n",
       "         1.57613996,  0.11917122, -0.25199043,  0.52034556, -0.21743938,\n",
       "         0.91346331,  0.56741057, -0.06581575,  0.27551143,  0.19373753,\n",
       "        -0.29813006,  0.07179912, -0.12440747,  0.04403999]),\n",
       " array([-0.43167285,  2.86310628,  0.11765572,  0.6927572 ,  0.33439715,\n",
       "         1.85191019,  0.15308516, -0.24204868,  0.46608227, -0.25878513,\n",
       "         0.97127119,  0.58665136, -0.10973206,  0.2755476 ,  0.20454612,\n",
       "        -0.35589354,  0.09596621, -0.16223522,  0.05943915]),\n",
       " array([-0.6040179 ,  3.35644666,  0.13671717,  0.65112408,  0.34019682,\n",
       "         2.14635766,  0.19433224, -0.23023687,  0.40424807, -0.29906764,\n",
       "         1.03344795,  0.60484538, -0.15634765,  0.27571572,  0.21461709,\n",
       "        -0.41642724,  0.12813948, -0.21154533,  0.0801436 ]),\n",
       " array([-0.77830722,  3.88264504,  0.16761906,  0.55675758,  0.33933019,\n",
       "         2.45312403,  0.24418475, -0.21721953,  0.33673633, -0.3385693 ,\n",
       "         1.09987502,  0.62223123, -0.20451768,  0.27594368,  0.2236679 ,\n",
       "        -0.47674786,  0.17088798, -0.27589485,  0.10787726]),\n",
       " array([-0.94897769,  4.42767568,  0.21783329,  0.40503507,  0.33087526,\n",
       "         2.76512455,  0.30417652, -0.20363305,  0.26546633, -0.37843093,\n",
       "         1.17008688,  0.63931124, -0.25304248,  0.27616801,  0.23147139,\n",
       "        -0.53322691,  0.22755856, -0.35998977,  0.14486916]),\n",
       " array([-1.11095288,  4.97592285,  0.29665745,  0.19746729,  0.31327399,\n",
       "         3.07497739,  0.37620355, -0.19005043,  0.19234109, -0.42032842,\n",
       "         1.24318757,  0.65676164, -0.30074808,  0.27633977,  0.23790421,\n",
       "        -0.58199675,  0.3025042 , -0.47005898,  0.19399524]),\n",
       " array([-1.26011918,  5.51184871,  0.4143498 , -0.05827957,  0.28409378,\n",
       "         3.37545591,  0.46264872, -0.17695715,  0.11921725, -0.46597955,\n",
       "         1.31783559,  0.67527456, -0.34655253,  0.27642815,  0.24297057,\n",
       "        -0.61952664,  0.40138114, -0.61434165,  0.25896264]),\n",
       " array([-1.39359306,  6.02159062,  0.58069505, -0.34983106,  0.24025666,\n",
       "         3.66000488,  0.56650459, -0.16473766,  0.04784951, -0.51667315,\n",
       "         1.39235321,  0.69539447, -0.389528  ,  0.27642056,  0.24679657,\n",
       "        -0.64325304,  0.5315299 , -0.80371445,  0.34454253]),\n",
       " array([-1.5097815 ,  6.49419307,  0.80316402, -0.66248462,  0.17873841,\n",
       "         3.9232733 ,  0.69144007, -0.15367066, -0.02019658, -0.57295067,\n",
       "         1.46494569,  0.71739679, -0.42895941,  0.27631954,  0.24959917,\n",
       "        -0.6520776 ,  0.70245206, -1.05248262,  0.45685054]),\n",
       " array([-1.60827968,  6.92225972,  1.0850129 , -0.98166033,  0.09750881,\n",
       "         4.16152392,  0.84173537, -0.14393249, -0.08363246, -0.63446354,\n",
       "         1.5339501 ,  0.74122336, -0.46438666,  0.2761376 ,  0.2516403 ,\n",
       "        -0.64655042,  0.92638753, -1.37935217,  0.60366354]),\n",
       " array([-1.68966187e+00,  7.30195969e+00,  1.42381149e+00, -1.29468666e+00,\n",
       "        -3.62900944e-03,  4.37278186e+00,  1.02201054e+00, -1.35608227e-01,\n",
       "        -1.41494723e-01, -6.99968600e-01,  1.59802280e+00,  7.66468354e-01,\n",
       "        -4.95614137e-01,  2.75891667e-01,  2.53178738e-01, -6.28664546e-01,\n",
       "         1.21898388e+00, -1.80858680e+00,  7.94743507e-01]),\n",
       " array([-1.75521934,  7.63250922,  1.810921  , -1.59163889, -0.12260881,\n",
       "         4.55668845,  1.23670227, -0.12870825, -0.19313812, -0.76742926,\n",
       "         1.65621877,  0.79240809, -0.52268312,  0.27559826,  0.25443116,\n",
       "        -0.60134741,  1.60002415, -2.37132894,  1.04210968]),\n",
       " array([-1.80669081,  7.91538656,  2.23228563, -1.86540884, -0.25524844,\n",
       "         4.71414786,  1.4893048 , -0.12318631, -0.23819186, -0.83422019,\n",
       "         1.70797608,  0.81807576, -0.54581766,  0.27526998,  0.25554995,\n",
       "        -0.56784719,  2.09413745, -3.10702231,  1.36015201]),\n",
       " array([-1.8460197 ,  8.15355087,  2.67052913, -2.11139641, -0.39594744,\n",
       "         4.84691116,  1.7814807 , -0.11895504, -0.2765114 , -0.89743421,\n",
       "         1.75305172,  0.84237965, -0.56536284,  0.27491346,  0.25661944,\n",
       "        -0.53121227,  2.73135033, -4.06480085,  1.76540696]),\n",
       " array([-1.87515919,  8.35083325,  3.107865  , -2.32714395, -0.53872158,\n",
       "         4.95721543,  2.11225087, -0.115897  , -0.30814612, -0.95425156,\n",
       "         1.79145062,  0.8642477 , -0.58173065,  0.27452851,  0.2576669 ,\n",
       "        -0.49397252,  3.5472491 , -5.30458807,  2.27572284]),\n",
       " array([-1.89593262,  8.51152795,  3.52898445, -2.51203537, -0.67825363,\n",
       "         5.04752698,  2.47754217, -0.11387258, -0.33332037, -1.00228798,\n",
       "         1.82336571,  0.88276469, -0.59535973,  0.27410836,  0.25868123,\n",
       "        -0.45802465,  4.5824306 , -6.89746573,  2.9084461 ]),\n",
       " array([-1.90994639,  8.64011983,  3.92310473, -2.66702658, -0.81066339,\n",
       "         5.12038018,  2.87033297, -0.11272745, -0.3524116 , -1.03983364,\n",
       "         1.84912635,  0.89726768, -0.60668768,  0.2736409 ,  0.25963217,\n",
       "        -0.42465708,  5.88086742, -8.92461954,  3.67721061]),\n",
       " array([ -1.9185465 ,   8.74107098,   4.28473642,  -2.79433964,\n",
       "         -0.9338395 ,   5.17828063,   3.28144629,  -0.11230164,\n",
       "         -0.36591278,  -1.06594   ,   1.86914816,   0.90738272,\n",
       "         -0.61613119,   0.27311095,   0.26048537,  -0.39463809,\n",
       "          7.48688573, -11.47390082,   4.58699972]),\n",
       " array([ -1.92280945,   8.81862902,   4.61322124,  -2.89710054,\n",
       "         -1.0473443 ,   5.22364529,   3.70075885,  -0.11244021,\n",
       "         -0.3743809 ,  -1.08037534,   1.88388412,   0.91301087,\n",
       "         -0.62407042,   0.27250335,   0.26121161,  -0.36831577,\n",
       "          9.44075517, -14.63288659,   5.62749321]),\n",
       " array([ -1.92356056,   8.87666466,   4.91143543,  -2.97895449,\n",
       "         -1.15201594,   5.25876301,   4.1183964 ,  -0.11300313,\n",
       "         -0.37838604,  -1.08351161,   1.89378531,   0.9142872 ,\n",
       "         -0.63083652,   0.27180653,   0.26179136,  -0.34571301,\n",
       "         11.77349146, -18.47751473,   6.76539754]),\n",
       " array([ -1.92141509,   8.91856616,   5.18414497,  -3.04370749,\n",
       "         -1.24942102,   5.28576369,   4.52552842,  -0.11387199,\n",
       "         -0.37847759,  -1.07620488,   1.89928279,   0.9115363 ,\n",
       "         -0.63670275,   0.2710162 ,   0.26221639,  -0.32662596,\n",
       "         14.50228148, -23.05623072,   7.93741531]),\n",
       " array([ -1.9168372 ,   8.94720973,   5.43641484,  -3.09502361,\n",
       "         -1.34128685,   5.3065845 ,   4.91465054,  -0.11495231,\n",
       "         -0.37517654,  -1.05970019,   1.90079754,   0.90523597,\n",
       "         -0.64188083,   0.2701382 ,   0.26249027,  -0.31073979,\n",
       "         17.62856776, -28.37133375,   9.04636776]),\n",
       " array([ -1.91020764,   8.96500212,   5.67234167,  -3.13618385,\n",
       "         -1.42900845,   5.322925  ,   5.27955004,  -0.11617225,\n",
       "         -0.3689901 ,  -1.03555364,   1.8987753 ,   0.89598626,\n",
       "         -0.64652367,   0.26918984,   0.2626287 ,  -0.29776325,\n",
       "         21.14061583, -34.36165434,   9.96309192]),\n",
       " array([ -1.9018865 ,   8.97396885,   5.89427279,  -3.1699073 ,\n",
       "         -1.51330506,   5.33619318,   5.61526783,  -0.11747948,\n",
       "         -0.36043415,  -1.00554354,   1.89373069,   0.88447345,\n",
       "         -0.65073445,   0.26819911,   0.2626597 ,  -0.28756179,\n",
       "         25.02082282, -40.89283183,  10.53556402]),\n",
       " array([ -1.8922552 ,   8.97585015,   6.10259019,  -3.19824669,\n",
       "         -1.59408394,   5.34745951,   5.91823878,  -0.11883796,\n",
       "         -0.35004602,  -0.97154793,   1.8862764 ,   0.87142105,\n",
       "         -0.65458032,   0.26720152,   0.26262266,  -0.28024984,\n",
       "         29.25541136, -47.76155677,  10.6044871 ]),\n",
       " array([ -1.88172685,   8.9721717 ,   6.29603819,  -3.22257863,\n",
       "         -1.67053515,   5.35744342,   6.18654873,  -0.12022504,\n",
       "         -0.33837543,  -0.93539098,   1.87711554,   0.85752944,\n",
       "         -0.65810715,   0.26623519,   0.26256519,  -0.27620138,\n",
       "         33.84186587, -54.71675408,  10.02251324]),\n",
       " array([ -1.87072564,   8.96427673,   6.47244819,  -3.24369538,\n",
       "         -1.74141952,   5.36654802,   6.42009476,  -0.12162856,\n",
       "         -0.3259544 ,  -0.89868802,   1.86699113,   0.84341625,\n",
       "         -0.66135151,   0.2653354 ,   0.26253754,  -0.27596038,\n",
       "         38.78918874, -61.4943233 ,   8.673658  ]),\n",
       " array([ -1.85964908,   8.95332991,   6.62960686,  -3.26197325,\n",
       "         -1.80544929,   5.37493759,   6.62047039,  -0.12304314,\n",
       "         -0.3132593 ,  -0.86273123,   1.85660844,   0.82957352,\n",
       "         -0.6643471 ,   0.26452985,   0.26258525,  -0.28006946,\n",
       "         44.10843684, -67.8558909 ,   6.49041872]),\n",
       " array([ -1.8488328 ,   8.94031682,   6.76599454,  -3.27756575,\n",
       "         -1.86163425,   5.38263336,   6.79055551,  -0.12446563,\n",
       "         -0.30068277,  -0.82844672,   1.84655905,   0.81635288,\n",
       "         -0.66712531,   0.26383594,   0.26274191,  -0.28886809,\n",
       "         49.79512404, -73.62002534,   3.46727923]),\n",
       " array([ -1.83853302,   8.92605782,   6.88120801,  -3.29056742,\n",
       "         -1.90949634,   5.38959863,   6.93393754,  -0.12589019,\n",
       "         -0.28852654,  -0.79642622,   1.83727272,   0.80397943,\n",
       "         -0.66971175,   0.26326004,   0.26302387,  -0.3023224 ,\n",
       "         55.80914591, -78.67794982,  -0.33080214]),\n",
       " array([ -1.82892927,   8.91123827,   6.97602686,  -3.30111624,\n",
       "         -1.94912136,   5.3957956 ,   7.05434244,  -0.12730447,\n",
       "         -0.27701409,  -0.76700798,   1.82900728,   0.7925838 ,\n",
       "         -0.67212183,   0.26279885,   0.26342829,  -0.31993817,\n",
       "         62.06019241, -82.99251808,  -4.76760501]),\n",
       " array([ -1.82013957,   8.89644106,   7.05220527,  -3.30943185,\n",
       "         -1.98107762,   5.40121196,   7.15521511,  -0.12868815,\n",
       "         -0.26631147,  -0.74036794,   1.82187009,   0.78223736,\n",
       "         -0.6743585 ,   0.26244179,   0.26393489,  -0.34078382,\n",
       "         68.40592996, -86.58497542,  -9.64589406]),\n",
       " array([ -1.81223659,   8.88216502,   7.11212329,  -3.31580617,\n",
       "         -2.00626147,   5.40586611,   7.23950667,  -0.13001458,\n",
       "         -0.25654371,  -0.71658759,   1.81585603,   0.77297757,\n",
       "         -0.67641368,   0.26217392,   0.26451098,  -0.36361883,\n",
       "         74.66612748, -89.51629481, -14.73005735]),\n",
       " array([ -1.80525773,   8.86882244,   7.15842076,  -3.32056982,\n",
       "         -2.02572792,   5.40980189,   7.30964794,  -0.13125507,\n",
       "         -0.24780017,  -0.6956852 ,   1.81088769,   0.76481873,\n",
       "         -0.67827327,   0.26197859,   0.26511835,  -0.38709127,\n",
       "         80.64955348, -91.86889443, -19.77787797]),\n",
       " array([ -1.79920825,   8.85672296,   7.19369451,  -3.32405395,\n",
       "         -2.04054656,   5.41308056,   7.36763964,  -0.13238414,\n",
       "         -0.240131  ,  -0.6776179 ,   1.80684908,   0.75775145,\n",
       "         -0.67992366,   0.26183963,   0.2657202 ,  -0.40994665,\n",
       "         86.18494577, -93.73207465, -24.57357986]),\n",
       " array([ -1.79406187,   8.84605857,   7.22029406,  -3.32655991,\n",
       "         -2.05170136,   5.41577356,   7.41517936,  -0.13338387,\n",
       "         -0.23354184,  -0.66227339,   1.80360973,   0.75173836,\n",
       "         -0.68135748,   0.26174274,   0.26628654,  -0.43119   ,\n",
       "         91.14591671, -95.19217684, -28.95307797]),\n",
       " array([ -1.78976306,   8.83690199,   7.24021679,  -3.32834172,\n",
       "         -2.06003641,   5.41795666,   7.45376709,  -0.13424612,\n",
       "         -0.22799326,  -0.64946793,   1.80104019,   0.74671281,\n",
       "         -0.6825766 ,   0.26167617,   0.26679692,  -0.45016675,\n",
       "         95.463099  , -96.32699505, -32.81562242]),\n",
       " array([ -1.78623299,   8.82922177,   7.25508225,  -3.32960072,\n",
       "         -2.06623906,   5.41970537,   7.48476496,  -0.1349722 ,\n",
       "         -0.22340746,  -0.63895756,   1.79902077,   0.74258307,\n",
       "         -0.68359234,   0.26163086,   0.26724066,  -0.46656117,\n",
       "         99.12270867, -97.2033658 , -36.12157378]),\n",
       " array([ -1.7833782 ,   8.82290913,   7.26615816,  -3.33048896,\n",
       "         -2.07084791,   5.42109133,   7.509416  ,  -0.13557094,\n",
       "         -0.21968008,  -0.63045984,   1.79744589,   0.739241  ,\n",
       "         -0.68442333,   0.26160015,   0.26761525,  -0.48033703,\n",
       "        102.15545096, -97.87681855, -38.88050737]),\n",
       " array([ -1.78109993,   8.81780859,   7.27441217,  -3.33111713,\n",
       "         -2.07427357,   5.42217975,   7.5288397 ,  -0.13605601,\n",
       "         -0.21669368,  -0.6236789 ,   1.7962255 ,   0.73657218,\n",
       "         -0.68509255,   0.26157929,   0.26792401,  -0.49165312,\n",
       "        104.62138682, -98.39238568, -41.13535508]),\n",
       " array([ -1.77930191,   8.81374517,   7.28057067,  -3.33156368,\n",
       "         -2.07682349,   5.42302793,   7.54402153,  -0.13644325,\n",
       "         -0.21432963,  -0.61832752,   1.79528467,   0.7344648 ,\n",
       "         -0.68562444,   0.26156506,   0.26817367,  -0.5007805 ,\n",
       "        106.59540858, -98.78594571, -42.94724371]),\n",
       " array([ -1.77789585,   8.81054479,   7.28517355,  -3.33188334,\n",
       "         -2.07872539,   5.42368469,   7.55580725,  -0.13674874,\n",
       "         -0.21247661,  -0.61414271,   1.79456241,   0.7328161 ,\n",
       "         -0.68604264,   0.26155527,   0.26837251,  -0.5080364 ,\n",
       "        108.15589045, -99.08571269, -44.38358387]),\n",
       " array([ -1.7768044 ,   8.80804703,   7.28862022,  -3.33211392,\n",
       "         -2.08014706,   5.42419062,   7.56490537,  -0.13698747,\n",
       "         -0.21103564,  -0.61089419,   1.79400976,   0.73153586,\n",
       "         -0.68636864,   0.26154846,   0.268529  ,  -0.51373905,\n",
       "        109.37719305, -99.31365911, -45.51008002]),\n",
       " array([ -1.77596212,   8.80611157,   7.29120578,  -3.33228154,\n",
       "         -2.08121201,   5.42457876,   7.57189709,  -0.13717263,\n",
       "         -0.20992213,  -0.60838725,   1.79358801,   0.73054761,\n",
       "         -0.68662101,   0.26154367,   0.26865103,  -0.51818117,\n",
       "        110.32555799, -99.48677333, -46.38619364]),\n",
       " array([ -1.77531513,   8.80462022,   7.29314852,  -3.33240426,\n",
       "         -2.08201127,   5.42487557,   7.57725081,  -0.13731541,\n",
       "         -0.2090659 ,  -0.60646148,   1.7932668 ,   0.72978833,\n",
       "         -0.68681534,   0.26154026,   0.2687455 ,  -0.52161761,\n",
       "        111.05748828, -99.61811926, -47.06315392]),\n",
       " array([ -1.77481992,   8.80347606,   7.29461029,  -3.33249467,\n",
       "         -2.0826121 ,   5.42510197,   7.58133874,  -0.13742502,\n",
       "         -0.20841002,  -0.60498748,   1.79302257,   0.72920707,\n",
       "         -0.68696435,   0.2615378 ,   0.26881824,  -0.52426193,\n",
       "        111.61971017, -99.71770228, -47.5836089 ]),\n",
       " array([ -1.77444193,   8.80260119,   7.29571143,  -3.33256165,\n",
       "         -2.08306438,   5.42527432,   7.58445333,  -0.13750886,\n",
       "         -0.20790911,  -0.60386238,   1.79283708,   0.72876336,\n",
       "         -0.68707825,   0.26153602,   0.26887401,  -0.52628845,\n",
       "        112.05000242, -99.79316204, -47.98219881]),\n",
       " array([ -1.77415404,   8.80193394,   7.29654169,  -3.33261149,\n",
       "         -2.0834052 ,   5.42540533,   7.5868223 ,  -0.13757282,\n",
       "         -0.20752741,  -0.60300544,   1.79269635,   0.72842537,\n",
       "         -0.6871651 ,   0.26153472,   0.26891663,  -0.52783666,\n",
       "        112.3784051 , -99.85031844, -48.28655768]),\n",
       " array([ -1.77393513,   8.80142605,   7.29716817,  -3.33264871,\n",
       "         -2.08366225,   5.4255048 ,   7.58862182,  -0.13762153,\n",
       "         -0.20723707,  -0.60235381,   1.79258964,   0.72816834,\n",
       "         -0.68723119,   0.26153376,   0.26894912,  -0.52901664,\n",
       "        112.62851072, -99.89359748, -48.5184391 ]),\n",
       " array([ -1.77376887,   8.80104004,   7.29764116,  -3.33267659,\n",
       "         -2.08385626,   5.42558026,   7.5899874 ,  -0.13765855,\n",
       "         -0.20701651,  -0.60185892,   1.79250878,   0.72797313,\n",
       "         -0.68728141,   0.26153305,   0.26897385,  -0.52991435,\n",
       "        112.81867726, -99.92636072, -48.69479898]),\n",
       " array([ -1.77364273,   8.80074698,   7.29799843,  -3.33269751,\n",
       "         -2.08400277,   5.42563746,   7.59102289,  -0.13768666,\n",
       "         -0.20684914,  -0.60148343,   1.79244754,   0.72782501,\n",
       "         -0.68731954,   0.26153252,   0.26899264,  -0.53059637,\n",
       "        112.96309068, -99.9511588 , -48.82875626]),\n",
       " array([ -1.77354709,   8.80052469,   7.29826839,  -3.33271325,\n",
       "         -2.08411345,   5.4256808 ,   7.59180764,  -0.13770798,\n",
       "         -0.20672221,  -0.60119874,   1.79240116,   0.7277127 ,\n",
       "         -0.68734845,   0.26153212,   0.26900689,  -0.53111398,\n",
       "        113.07265596, -99.96992559, -48.93040498]),\n",
       " array([ -1.77347462,   8.8003562 ,   7.29847242,  -3.3327251 ,\n",
       "         -2.08419709,   5.42571363,   7.59240209,  -0.13772415,\n",
       "         -0.20662603,  -0.60098301,   1.79236605,   0.7276276 ,\n",
       "         -0.68737037,   0.26153183,   0.26901771,  -0.5315065 ,\n",
       "        113.15572296, -99.98412652, -49.00747947]),\n",
       " array([ -1.77341973,   8.80022854,   7.29862666,  -3.33273404,\n",
       "         -2.08426031,   5.42573848,   7.59285224,  -0.1377364 ,\n",
       "         -0.20655316,  -0.6008196 ,   1.79233948,   0.72756313,\n",
       "         -0.68738697,   0.2615316 ,   0.26902591,  -0.53180399,\n",
       "        113.21866622, -99.99487162, -49.06588735]),\n",
       " array([  -1.77337816,    8.80013185,    7.29874329,   -3.33274078,\n",
       "          -2.08430811,    5.4257573 ,    7.59319304,   -0.13774567,\n",
       "          -0.20649799,   -0.60069587,    1.79231937,    0.72751432,\n",
       "          -0.68739955,    0.26153143,    0.26903212,   -0.53202934,\n",
       "         113.26634136, -100.00300137,  -49.11013034]),\n",
       " array([  -1.77334669,    8.80005865,    7.29883147,   -3.33274587,\n",
       "          -2.08434425,    5.42577154,    7.59345099,   -0.1377527 ,\n",
       "          -0.20645621,   -0.6006022 ,    1.79230415,    0.72747737,\n",
       "          -0.68740907,    0.26153131,    0.26903682,   -0.5322    ,\n",
       "         113.30244074, -100.00915209,  -49.1436327 ]),\n",
       " array([  -1.77332287,    8.80000323,    7.29889816,   -3.33274971,\n",
       "          -2.08437158,    5.42578232,    7.59364621,   -0.13775801,\n",
       "          -0.2064246 ,   -0.6005313 ,    1.79229263,    0.7274494 ,\n",
       "          -0.68741627,    0.26153121,    0.26904038,   -0.5323292 ,\n",
       "         113.32976859, -100.01380537,  -49.16899556]),\n",
       " array([  -1.77330485,    8.79996129,    7.2989486 ,   -3.33275262,\n",
       "          -2.08439225,    5.42579047,    7.59379394,   -0.13776204,\n",
       "          -0.20640067,   -0.60047764,    1.79228392,    0.72742823,\n",
       "          -0.68742173,    0.26153114,    0.26904307,   -0.532427  ,\n",
       "         113.35045256, -100.01732569,  -49.18819285])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "katsayilar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada HER BİR LAMBDA değerine karşılık, DEĞİŞKEN SAYISI KADAR beta katsayıları türetilmiş oldu. Şimdi bu durumu gözlemleyebilmek adına bir grafik oluşturucaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca() # nesne özelliği tanımladık.\n",
    "ax.plot(lambdalar, katsayilar) # neyi görselleştiricez? lambdaları görselleştiricez ve bunlara karşılık katsayıları görselleştiricez.\n",
    "# Yani her bir lambda değerine karşılık gelecek şekilde katsayıların nasıl oluştuğu bilgisine erişmeye çalışıcaz.\n",
    "ax.set_xscale(\"log\") # katsayılar birbirinden farklı olabilecek olduğundan dolayı, hepsini görebilmek adına bir ölçek değiştirme işlemi.\n",
    "# Logaritmik dönüşüm yaptık."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Farklı lambda değerlerine karşılık olacak şekilde, farklı katsayıların nasıl oluştuğu bilgisi bizimle paylaşıldı. Buradaki birbirinden farklı renkler, katsayıların değerlerini ifade ediyor. x ekseni, lambda değerlerini ifade ediyor. Yani burada, farklı lmbda değerlerine karşılık, elimizdeki parametrelerin (katsayıların yani) nasıl değiştiği bilgisi verilmiş oluyor. Burada, lambdalar arttıkça kafasına vura vura(lol) bunları sıfıra yaklaştırmış. Ridge regresyon, anlamsız parametreleri sıfıra yaklaştırır. Bu katsayılar öyle bir yerde durmalı ki, HK ort. karekökü değerini ya da toplam hata kare değerini minimum yapmalı. Bunun da hangi değerlere karşılık geldiği bilgisini değerlendirmiş olacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonraki bölümde, amacımız optimum lambda değerini hataları da göz önünde bulundurarak seçmek olacak. Burada yaptığımız, farklı lambda değerlerine karşılık, beta katsayılarımızın ne olduğunu, değerlerinin nasıl değiştiğini görsel bir teknik ile ele almaktı."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.005)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model #alpha değerimiz en son 0.005 olmuş"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = Ridge().fit(X_train, y_train) #model nesnemiz. kurmuş olduğumuz modelimiz. MAKİNE ÖĞRENMESİ MODELİ KURDUM DEMEK BU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ridge_model.predict(X_train) #tahmin için predict kullanıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 376.25245449,  803.38498121,  496.17669652,  112.69554648,\n",
       "        427.60020221, 1003.6309402 ,  153.45713944,  361.33880956,\n",
       "        483.29143665,  916.91439669])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10] #bunlar tahmin edilen değerler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183     125.0\n",
       "229    1940.0\n",
       "286     940.0\n",
       "102     375.0\n",
       "153     100.0\n",
       "320     960.0\n",
       "135      90.0\n",
       "213     100.0\n",
       "308     750.0\n",
       "161     657.0\n",
       "Name: Salary, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10] #bunlar gerçek değerler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289.34470696006565"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train hatası\n",
    "RMSE = np.sqrt(mean_squared_error(y_train, y_pred)) #rmse'yi hesapla dedik. Neyin üzerinden hesaplayacak? ygerçek ve ytahmin.\n",
    "RMSE #train setine ilişkin rmse. TRAİN SETİ ÜZERİNDEN VALİDE EDİLMEMİŞ HATA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu bizim train hatamız. Ama valide edilmemiş train hatamız. Bunu valide etmek istersek CV kullanmamız gerekiyor. Yine traine ilişkin bir hata alacağız ama valide edilmiş bir train hatası alacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351.3931585606319"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.mean(-cross_val_score(ridge_model, X_train, y_train, cv = 10, scoring = \"neg_mean_squared_error\")))\n",
    "# CV YÖNTEMİ İLE 10 KATLI HATA HESAPLAMA İŞLEMİ. DAHA DÜŞÜK OLMASI OLMAMASI DEĞİL, bu kısımdaki hata daha doğru bir hata. \n",
    "# Daha doğru bir hata elimizde olursa, model optimizasyonu için daha doğru bir hata bulundurmuş oluruz ve buna göre hareket ederiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ama biz ileriki bölümlerde CV'ı burada yapmayacağız. İlkel yöntem ile train üzerinden train hatamızı bulmuş olacağız. Zira model optimizasyonu bölümünde CV yöntemiz ile hata hesaplıyo olucaz. Yani bunu model optimizasyonunda yapıcaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test hatası\n",
    "y_pred = ridge_model.predict(X_test)#test setine ilişkin tahmin edilen değerlere erişeceğiz. modeli xtest seti üzerinde tekrar çalıştırıcaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356.80829057302384"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, y_pred)) # buradaki y_pred artık, test bağımsız değişkenleri kullanılarak hesaplanmış olan testin\n",
    "# bağımlı değişkenleri, tahmin edilen değerleri. y_test, test setinin y değerlerini yani gerçek bağımlı değişken değererine erişmiş oluruz.\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neden Model Tuning?**\n",
    "modellemek nedir? modellemek, veriseti içerisinde bapımlı ve bağımsız değişkenler arasındaki ilişkiyi modellemek. Yani öğrenmek. Bu öğrenme işlemini üzerindn tahmin yapabiliriz. \n",
    "Tahmin etmek? kurmuş olduğumuz yani öğrenmiş olduğumuz veriseti yapısını kullanarak, onu bir fonksiyonla temsil ederek, ya da bir karar kuralıyla temsil ederek, tahminde bulunmak. \n",
    "model tuning neden? \n",
    "lamdanın ne olması gerektiğini bilmiyoruz. Bu yüzden deneme yanılma yoluyla, hiperparametreleri tune ediyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356.80829057302384"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model = Ridge(1).fit(X_train, y_train) #ridge ile train üzerinden modelimizi fit ettik. buradaki 1, alpha değerimiz.\n",
    "\n",
    "y_pred = ridge_model.predict(X_test) #bu modeli kullanarak, test yapmak aracılığıyla predict fonksiyonunu kullanarak, test setimizin bağımsız\n",
    "#değişken değerlerini aldık. ve tahmin ettik. neyi tahmin ettik? test setinin bağımlı değişkenlerini\n",
    "\n",
    "np.sqrt(mean_squared_error(y_test, y_pred)) #tahmin edilen bu bağımlı değişken değerleri ile test setinin gerçek değerlerini karşılaştırarak\n",
    "#Hatamızı hesapladık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([779, 716, 399, 669, 789, 849, 732,  77, 694, 752, 591, 664, 207,\n",
       "       347, 411, 181, 919,  13, 731, 565, 940, 227, 954, 677, 842, 485,\n",
       "       501, 821,  84, 902, 718,  95, 127, 251,  98, 527, 547, 359, 324,\n",
       "       115, 675, 898, 950, 118, 608, 882, 345, 318, 260, 550, 755,  35,\n",
       "       579, 771, 758, 690, 676, 239, 418, 242, 486, 978, 958, 665, 730,\n",
       "       899, 372, 484, 131, 750,  49, 742, 835, 494, 917, 523, 121, 992,\n",
       "       279, 428, 207, 857, 472, 157, 968, 173,  97, 673, 490, 810, 452,\n",
       "       638, 149, 985, 998, 856, 412, 231, 396, 407])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,1000,100) #bşz hangi lambda değeri min verecek bilmiyoruz. o halde birçok değeri deneyelim. random sayılar.\n",
    "# 0-1000 arası random 100 sayı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdalar1 = np.random.randint(0,1000,100) #bu işlem ile hiperparametreleri tune etmiş oluyoruz yani model tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdalar2 = 10**np.linspace(10,-2,100)*0.5 #önceki bölümde oluşturduğumuz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([859, 107, 534, 963, 851, 409, 994, 272, 508, 679, 787, 678, 507,\n",
       "       454, 350, 455, 965, 885, 670, 361, 238, 703, 568, 905, 278, 395,\n",
       "       680, 259, 914, 561, 228, 604, 988, 666, 201, 831, 381, 297,  94,\n",
       "       894, 176, 290, 158, 261, 862, 963, 436, 828, 657,  38, 137,  37,\n",
       "       426, 713, 237, 129,  22, 145, 375, 548, 748, 366, 959, 522,  99,\n",
       "       434, 439, 872, 650,  52, 420,  16, 326, 411, 396, 364, 175, 271,\n",
       "       670, 336, 731, 997, 362, 716,  65, 652, 990, 117, 389, 656, 974,\n",
       "       661, 575, 293, 794, 943, 260, 216, 851, 369]),\n",
       "        cv=10, normalize=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv = RidgeCV(alphas = lambdalar1, scoring = \"neg_mean_squared_error\", cv = 10, normalize = True)\n",
    "ridgecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Çeşitli denemeleri yaptıktan sonra, çeşitli lambda değerlerine karşılık, çeşitli hataları hesaplamış oldu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv.alpha_ #bunun ile optimum parametreyi alabiliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final modeli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_tuned = Ridge(alpha = ridgecv.alpha_).fit(X_train, y_train) #tune edilmiş final modelimiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356.3699926835376"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ridge_tuned.predict(X_test) #tuned reidge ile xtest kullanarak y tahmin et.\n",
    "np.sqrt(mean_squared_error(y_test, y_pred)) #test hatamız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regresyon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerekli Kütüphaneler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeCV, LassoCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veri Seti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hitters.csv\")\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "dms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\n",
    "\n",
    "y = df[\"Salary\"]\n",
    "\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
    "\n",
    "X = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hikayemiz yine aynı. Yukarıda olduğu gibi maaş tahmini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AtBat</th>\n",
       "      <th>Hits</th>\n",
       "      <th>HmRun</th>\n",
       "      <th>Runs</th>\n",
       "      <th>RBI</th>\n",
       "      <th>Walks</th>\n",
       "      <th>Years</th>\n",
       "      <th>CAtBat</th>\n",
       "      <th>CHits</th>\n",
       "      <th>CHmRun</th>\n",
       "      <th>CRuns</th>\n",
       "      <th>CRBI</th>\n",
       "      <th>CWalks</th>\n",
       "      <th>League</th>\n",
       "      <th>Division</th>\n",
       "      <th>PutOuts</th>\n",
       "      <th>Assists</th>\n",
       "      <th>Errors</th>\n",
       "      <th>Salary</th>\n",
       "      <th>NewLeague</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>315</td>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>14</td>\n",
       "      <td>3449</td>\n",
       "      <td>835</td>\n",
       "      <td>69</td>\n",
       "      <td>321</td>\n",
       "      <td>414</td>\n",
       "      <td>375</td>\n",
       "      <td>N</td>\n",
       "      <td>W</td>\n",
       "      <td>632</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>475.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>479</td>\n",
       "      <td>130</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "      <td>1624</td>\n",
       "      <td>457</td>\n",
       "      <td>63</td>\n",
       "      <td>224</td>\n",
       "      <td>266</td>\n",
       "      <td>263</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>880</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>480.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>141</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5628</td>\n",
       "      <td>1575</td>\n",
       "      <td>225</td>\n",
       "      <td>828</td>\n",
       "      <td>838</td>\n",
       "      <td>354</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>500.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>321</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>42</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>396</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>N</td>\n",
       "      <td>E</td>\n",
       "      <td>805</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>91.5</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>594</td>\n",
       "      <td>169</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>4408</td>\n",
       "      <td>1133</td>\n",
       "      <td>19</td>\n",
       "      <td>501</td>\n",
       "      <td>336</td>\n",
       "      <td>194</td>\n",
       "      <td>A</td>\n",
       "      <td>W</td>\n",
       "      <td>282</td>\n",
       "      <td>421</td>\n",
       "      <td>25</td>\n",
       "      <td>750.0</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AtBat  Hits  HmRun  Runs  RBI  Walks  Years  CAtBat  CHits  CHmRun  CRuns  \\\n",
       "1    315    81      7    24   38     39     14    3449    835      69    321   \n",
       "2    479   130     18    66   72     76      3    1624    457      63    224   \n",
       "3    496   141     20    65   78     37     11    5628   1575     225    828   \n",
       "4    321    87     10    39   42     30      2     396    101      12     48   \n",
       "5    594   169      4    74   51     35     11    4408   1133      19    501   \n",
       "\n",
       "   CRBI  CWalks League Division  PutOuts  Assists  Errors  Salary NewLeague  \n",
       "1   414     375      N        W      632       43      10   475.0         N  \n",
       "2   266     263      A        W      880       82      14   480.0         A  \n",
       "3   838     354      N        E      200       11       3   500.0         N  \n",
       "4    46      33      N        E      805       40       4    91.5         N  \n",
       "5   336     194      A        W      282      421      25   750.0         A  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 20)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8256653.399850373, tolerance: 3898.686956380658\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "lasso_model = Lasso().fit(X_train, y_train) #Lasso() içine lambda değeri gelecek. Şimdi boş bıraktık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model #lambda vermedik. lambdayı 1 almış."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-5.587450677336392"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.intercept_ #modelin içerisinden sabiti alabiliyoruz. biliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.74875691e+00,  8.59204135e+00,  6.67993798e+00, -3.06715333e+00,\n",
       "       -1.91843070e+00,  5.32372890e+00,  8.39184117e+00, -1.63172447e-01,\n",
       "       -8.22311277e-02, -3.93602861e-01,  1.71118530e+00,  6.55730545e-01,\n",
       "       -6.48379405e-01,  2.59815358e-01,  2.73041157e-01, -4.41440454e-01,\n",
       "        8.54474011e+01, -9.59701213e+01, -2.13086605e+01])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.coef_ #Katsayılar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#farklı lambda degerlerine karsilik katsayilar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5469.558741420507, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6540.147679615766, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4001.7561375573277, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5357.774935614318, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5543.6113204322755, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38977.90211556107, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4436895.415748725, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6555245.313878526, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7517635.389992702, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7913116.552938912, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8063057.666015295, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8147851.972007792, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8195503.9251405895, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8222772.970408581, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8238618.061152169, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247931.056261499, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8254112.78308281, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8256643.474169184, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8256663.517485517, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8255732.406295814, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8254488.032216581, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8253238.172401862, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8252116.626715336, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8251167.5991485445, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8250392.226499416, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8249772.805943242, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8249285.457095996, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8248906.058581414, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8248612.895174987, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8248387.6137469215, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8248215.191106203, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8248083.606041499, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247983.409284998, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247907.234834625, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247849.397090834, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247805.522216822, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247772.2618123125, tolerance: 3898.686956380658\n",
      "  positive)\n",
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8247747.060921393, tolerance: 3898.686956380658\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso() #lasso nesnesi oluşturduk\n",
    "coefs = [] #katsayılar listesi oluşturduk. boş.\n",
    "alphas = 10**np.linspace(10,-2,100)*0.5 #bir alphas seti oluşturduk.\n",
    "for a in alphas:\n",
    "    lasso.set_params(alpha = a) #alphayı sırayla deniyoruz yani.\n",
    "    lasso.fit(X_train, y_train) #bu alphaya göre fit ediyoruz.\n",
    "    coefs.append(lasso.coef_) #coef-katsayı değerini listeye ekle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca() #görselleştiriyoruz. ax isimli nesne oluşturduk.\n",
    "ax.plot(alphas,coefs)\n",
    "ax.set_xscale(\"log\") #katsayıları gözlemleyebilmek adına, görünme adına bir ayarlama işlemi gerçekleştiriyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Özet ile, lasso, yeteri kadar büyük lambda değerleri gelirse ben bu katsayları sıfıra yaklaştırırım diyor. Bu şekilde de farklı lambda değerlerine kaarşılık katsayıların ne olduğu bilgisine erişmiş olduk. Görsel ile. \n",
    "Görselde, görünür bir şekilde katsayıların değişimi ve bu değişime ilişkin bilgiyi sunmuş oldu. Belirli bir noktaya kadar katsayılar sıfırın etrafındayken, sıfıra yaklaşmışken, belirli bir noktadan sonra ise artık sıfırlar. Ridge de ise bu sayılar sıfıra yaklaşıyor ama asla sıfır olmuyordu. Lassoda ise, parametre değerleri arttıkça, değiştikçe, modelimizin içinde kullanılan beta katsayılarının değerleri de sıfır olmuş ya da sıfıra yaklaşmış."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model #model tuning de bu alphayı optimize etmeye çalışıcaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([377.26270596, 786.51524513, 495.14140718, 117.19492966,\n",
       "       429.04228506])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.predict(X_train)[0:5] #train seti için tahmin etme işlemi yaptık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 609.18826367,  696.96810702, 1009.06157391,  412.22773375,\n",
       "        409.25851712])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.predict(X_test)[0:5] #test seti için de tahmin etme işlemi yaptık. Yani test setinin bağımsız değişkenlerini kullanarak, test\n",
    "# setinin bağımlı değişkenlerini tahmin et demek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hatırlatma:** \n",
    "\n",
    "* verisetimizi eğitim ve test olarak ikiye ayırdık. Yani aslında elimizde 2 tane ayrı veriseti var. Bu iki ayrı veriseti içerisinde, bağımsız değişkenler ve bağımlı değişken var. Dolayısıyla istersem eğitim seti içerisinde bir model kurup, bu modelle ilgili konuşabilirim. İstersem test seti ile bir model kurup, bununla ilgili konuşabilirim. İkisi de verinin kendisi. Sadece ikiye böldük. \n",
    "\n",
    "* Ne için ikiye bölmüştük? Eğitim seti ile modelimizi eğitiyoruz, yani içerisinde bağımsız değişkenleri ve bağımlı değişkenleri olan eğitim seti ile model kurmak için ilgileniyoruz. Modeli kurduk. Bu kurmuş olduğumuz modeli kullanarak örneğin eğitim seti içerisindeki bağımsız değişken değerlerini kullanıp, bağımlı değişkeni tahmin ediyorum(yukarıda parantez içi X_train olan). Yine train seti ile kurmuş olduğumuz modeli kullanarak test setinin içerisindeki bağımsız değişkenleri kullanıp, test seti içerisindeki bağımlı değişkenin değerlerini tahmin ediyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso_model.predict(X_test) #test hatasını buluyoruz bu kısımda. test setindeki bapımsız değişken değerleri kullanarak, test setinin\n",
    "#içerisindeki bağımlı değişkenin değerini tahmin et diyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "356.09758845540324"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred)) #Hata kareler ort. Karekökü değerimizi hesapladık. İlkel test hatamız. Optimize edilmedi. ondan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.414227981323662"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred) #r^2 skoruna bakıyoruz. Modelin açıklanabilirliğini ifade etmektedir.Regresyon problemleri için ok önemli bir ölçüt.\n",
    "# Bağımsız değişkenlerce, bağımlı değişkendeki değişikliğin açıklanma yüzdesidir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(10,-2,100)*0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv_model = LassoCV(alphas = alphas, cv = 10, max_iter = 100000).fit(X_train, y_train) #aranacak alphaları verdik. np.sqrt düştü."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201.85086292982749"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_tuned = Lasso().set_params(alpha = lasso_cv_model.alpha_).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_tuned = Lasso(alpha = lasso_cv_model.alpha_).fit(X_train, y_train) #üstteki ile aynı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lasso_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363.68327080374456"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred)) #final modelimizin test hatası"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat         -1.052276\n",
       "Hits           5.342648\n",
       "HmRun          0.000000\n",
       "Runs           0.000000\n",
       "RBI            0.000000\n",
       "Walks          2.640006\n",
       "Years          0.000000\n",
       "CAtBat        -0.174125\n",
       "CHits          0.249805\n",
       "CHmRun        -0.000000\n",
       "CRuns          1.035075\n",
       "CRBI           0.469281\n",
       "CWalks        -0.186771\n",
       "PutOuts        0.272541\n",
       "Assists        0.170528\n",
       "Errors        -0.000000\n",
       "League_N       0.000000\n",
       "Division_W    -0.000000\n",
       "NewLeague_N    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lasso_tuned.coef_, index = X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tune edilmiş lasso modelimizin katsayılarını, bu değişkenlerin isimleriyle birlikte getirdi. Burada sıfır olan katsayılar, aslında anlamsız olan değişkenler formuna dönmüş oluyor. Yani bunların katsayısı sıfır olduğunda, bunlar maaşa olan etkilri açısından sıfırlanmış oluyor. Amacımız neydi? oyunculara maaş teklifi yapmaktı. Katsayısı sıfır olan değşkenler, maaşa etkili olmayan değişkenlerdir. Diğerlerinin de etkilerini görüyoruz. Mesela en etkilisi Hits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet Regresyon Modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerekli Kütüphaneler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import RidgeCV, LassoCV,ElasticNetCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Veri Seti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Hitters.csv\")\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "dms = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\n",
    "\n",
    "y = df[\"Salary\"]\n",
    "\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
    "\n",
    "X = pd.concat([X_, dms[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustafa/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8487984.799367314, tolerance: 3898.686956380658\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "enet_model = ElasticNet().fit(X_train, y_train) #Modeli kurduk elasticnet ile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.86256172,   8.70489065,   5.10426375,  -2.89875799,\n",
       "        -1.28642985,   5.24343682,   6.04480276,  -0.14701495,\n",
       "        -0.21566628,  -0.7897201 ,   1.80813117,   0.80914508,\n",
       "        -0.61262382,   0.26816203,   0.27172387,  -0.36530729,\n",
       "        19.2186222 , -31.16586592,   8.98369938])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.coef_ #katsayılara eriştik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.465955602112672"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.intercept_ #sabit terime eriştik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([325.74706292, 776.06632333, 522.86508419, 107.64091955,\n",
       "       449.03139566, 997.76095723,  99.78828622, 311.33763086,\n",
       "       418.50335021, 879.9502608 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tahmin\n",
    "enet_model.predict(X_train)[0:10] #kurduğumuz model aracılığıyla tahmin işlemi gerçekleştirdik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 577.79111731,  617.33202224, 1031.39113156,  364.95861575,\n",
       "        489.51894393,  300.74185842,  604.522666  ,  465.34678732,\n",
       "        901.44473965,  703.20357123])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.predict(X_test)[0:10] # bu da test setimiz için"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = enet_model.predict(X_test) # test setinin bağımsız değişkenleri kullanılarak tahmin edilmiş olan test setinin bağımlı değişkenleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357.16765481812456"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred)) #Test hatamızı hesapladık. ilkel test hatamız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4107022246932688"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, y_pred) #açıklanabilirlik yüzdemiz. %41miş."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(10,-2,100)*0.5 #alpha kısmını boş bırrakıp kendisine de bırakabilirdik alpha seçimini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3249.9483078774065, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4337.0031515117735, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5751.424793953076, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7379.3536751475185, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 403437.83379287086, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 830826.1625857931, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 130519.54009749927, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16208.632716404274, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26112.427357131615, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3770.5528232548386, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 303635.40935038775, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1003274.7433232795, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4450942.483001597, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5076765.912003902, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5391765.4882389065, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5573248.080126847, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5681629.329845726, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5747782.476358873, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5789065.553178489, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5815540.980950192, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5833100.856065556, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5845191.968547792, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5853820.205874094, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5860154.834864625, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5864893.009197081, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5868472.143276386, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5867746.131421645, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5873611.935769858, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5875662.91901302, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5876891.765247937, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5877773.7306735795, tolerance: 3241.4244490642723\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5068.215616211295, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 204999.40594183654, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 788560.4630890582, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2293668.9624292003, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3430169.558765143, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4266665.6817361405, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4870647.824705881, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5297167.790290996, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5584497.026815729, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5754281.625966262, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5809358.8719084365, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5722512.07287441, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5393143.788505832, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4434425.352435726, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 484441.14557889104, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2783414.553125971, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5975136.857157623, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6820441.679086207, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7120638.716287084, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7333370.774735168, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7414553.8166541755, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7443957.25269958, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7439651.712411287, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7404015.091914235, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7326382.329530702, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7167831.011255495, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6772597.1462745825, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4619307.114603519, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5534121.594606193, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6869433.412145052, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7182664.577926054, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7315966.557040219, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7386668.714566445, tolerance: 3617.313788867113\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11511.098314305767, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 81379.24525391497, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 241727.7663502153, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 680957.6204400472, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1638971.1919250274, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2297235.3929483118, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2818353.6075719846, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3097616.6249669557, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3184180.1849360587, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3031082.673613499, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2463821.216824429, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 917192.2949605063, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 132457.00496974587, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1852773.1205343045, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4556079.463359764, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5576668.585179399, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6060811.212795469, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6323270.55232248, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6477932.480250879, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6574695.78474526, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6624598.960455365, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6682253.44013645, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6713509.8039796585, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6735111.156456739, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6750665.369385239, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6761964.2088970775, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6770192.132506315, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6776191.462598051, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6780573.482316624, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6783782.767546178, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6786141.36082849, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6787881.555845235, tolerance: 3214.815928601271\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20504.169906245545, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 71606.78684741631, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 122229.86725496873, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 182682.9862159118, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 249424.51341372915, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1123238.607676329, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2148501.1980449427, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2745746.288848931, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3153414.0195824727, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3392561.371345115, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3445739.3684961647, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3235674.156990137, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2517427.1408836944, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 520968.42857688665, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56213.692063769326, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3271147.0637032194, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5516096.0312580345, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6385036.322790788, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6810502.56764217, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7023285.981756598, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7152847.162759571, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7232464.5336002465, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7283621.304860798, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7317942.1647773, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7341835.158066197, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7358938.759963405, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7364032.720828833, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7381303.943953183, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7388673.043556834, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7393671.591843337, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7397333.992415994, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7400049.191358443, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7402068.964676186, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7403575.106511123, tolerance: 3528.2752057703365\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33665.31176728569, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27693.861888278276, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 77056.5270178467, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 128742.79618379101, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 234841.14284528233, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 655320.7999402229, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1585529.0400160104, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2359230.3793902965, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2943774.4824308017, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3878962.3829682637, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4062263.568787786, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4058048.08904521, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3711498.016512597, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2542575.887748069, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 220218.34094401076, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1865508.5642732037, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5578616.62400881, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6542007.228004435, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7017443.548138923, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7257492.536532833, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7388367.455381999, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7463707.9150624, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7494212.162011164, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7537511.397209741, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7556544.730320456, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7568392.799619169, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7576252.732367165, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7581520.439572317, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7585036.025497109, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7587359.901802679, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7588880.14269169, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7589866.42233284, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7590503.358587458, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7590914.623347552, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7591181.315363068, tolerance: 3453.938971338275\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 51104.90978922695, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 86001.20448155887, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 124299.8720545657, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 163171.28460214473, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 199613.01632316038, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 226297.59086185694, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 236325.4835075084, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 222091.50699202158, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 175489.45678951778, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 92900.06560351886, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5688.245361143723, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2438817.7080245325, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4551640.489719147, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5666781.226703019, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6274516.978036382, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6618924.050770857, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6819925.021459719, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6939888.740255379, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7012853.6508121425, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7058050.445154447, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7076979.858016124, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7105751.217372743, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7116703.743248894, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7127849.608577753, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7131404.055197751, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7134893.576487858, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7137346.992030641, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7139015.166143461, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7140147.34596425, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7140919.228947103, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7141449.45358335, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7141817.186153318, tolerance: 3582.448344789122\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4891.730603482574, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21878.274470465258, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56824.895237173885, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 200353.91866120696, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 342303.4562176317, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 531378.5049928632, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1659301.3143067397, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2711701.2209533695, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3504700.317143725, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4070925.3229236156, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4459448.610546291, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4704667.308094735, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4821661.201298864, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4799994.378885162, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4581093.932890203, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3967734.813671618, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2125357.815107518, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 155148.4609091971, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3641768.368037978, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5531980.263947714, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6233312.054884991, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6577908.211155202, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6773934.301590421, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6869192.6250541555, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6977555.60243807, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7034830.798080674, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7073919.740577376, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7101814.537381195, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7121974.106257992, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7136638.0856358735, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7147356.820128555, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7155226.875893336, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7161030.438994968, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7165327.889516371, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7168522.250851156, tolerance: 3343.765513901127\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16776.725272901356, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 313915.672217153, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 438819.2484661862, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 903233.6317603756, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1444700.7935627736, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1710822.521310078, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1578407.4658559486, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 787482.6696772408, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 288554.60305004753, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16065.32960353233, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3295353.004159987, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5441477.641653936, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6368596.005842345, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6830870.436434711, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7082059.059472668, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7225920.736867637, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7311264.696978303, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7363290.948135563, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7395832.277203264, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7416780.639864617, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7430735.873212153, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7440400.53226293, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7447361.139148424, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7452547.105506297, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7453614.11731339, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7459988.382953709, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7462722.527470434, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7464625.655564147, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7466082.051318463, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7467208.534955391, tolerance: 3701.0815904731803\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 68689.91805270687, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 202989.70445531793, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 332828.86355972476, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 880949.4120719805, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2098415.543933302, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3098659.2639973788, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3817727.7534724036, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4305199.30347791, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4592808.140962101, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4677254.178425961, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4487185.564702912, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3736616.425153911, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1028870.7443045452, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 56857.20957745798, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5137785.242497967, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6520863.618900159, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7062855.429016954, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7301030.614184812, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7462897.773822652, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7549964.3920026105, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7598803.374622478, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7628772.888019682, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7647769.367456485, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7660037.809739837, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7668031.832936037, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7673234.9570092335, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7676587.9230428375, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7678713.422115948, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7680033.839958056, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7680836.232888917, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7681312.767118299, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7681589.05301848, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7681745.057668343, tolerance: 3693.906712970403\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41948.83756121248, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 896764.1413878445, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2063539.4043554347, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3320899.4540681653, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4463993.9183287285, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5375668.590075216, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6228631.126157569, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6520080.941147082, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 6894283.320190471, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7061780.991338048, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7159825.696967084, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7220550.207830748, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7258207.007661328, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7281265.424995655, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7294955.722820314, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7302573.404775986, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7306264.5986957615, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7307479.59963283, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7307219.086574686, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7306167.637442122, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7304775.828111319, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7303321.303286475, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7301959.051428854, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7300762.328066937, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n",
      "/Users/mvahit/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 7299753.91767567, tolerance: 3682.649486336423\n",
      "  tol, rng, random, positive)\n"
     ]
    }
   ],
   "source": [
    "enet_cv_model = ElasticNetCV(alphas = alphas, cv = 10).fit(X_train, y_train) #crossvalidation sayımızı 10 dedik. 10 katlı cv işlemi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5748.784976988678"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv_model.alpha_ #optimum parametresine bakalım. lambdamız bu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-31.463121225641316"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv_model.intercept_ #sabitimiz bu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.61111381,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.        ,  0.        ,  0.11212622,  0.        ,\n",
       "        0.25252702,  0.18656722,  0.00444355,  0.30988823,  0.        ,\n",
       "       -0.        ,  0.        , -0.        ,  0.        ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_cv_model.coef_ #katsayılarımız bunlar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ElasticNet ne yapıyordu? Ridge tarzı cezalandırma, Lasso tarzı değişken seçimi yapıyordu. İkisinin iki güzel özelliğini bir araya getiriyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet_tuned = ElasticNet(alpha = enet_cv_model.alpha_).fit(X_train, y_train) #bulunan optimum alpha değeri ile final modelimizi kurduk. Tune edilmiş modelimizi fit ettik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = enet_tuned.predict(X_test) # final modelini kullanarak, tahmin işlemi gerçekleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393.9753065850553"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, y_pred)) #test setimiz için hatamızı hesaplayalım."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Her bir model için elde etmiş olduğumuz final modeli neticesindeki test hatalarını karşılaştırarak örneğin böyle bir problem için hangi modelin kullanılarak modelleme işlemi yapılacağına da en son karar vermemiz gerekiyor. \n",
    "* Yöntemimiz: Birçok aday model oluşturup, bu aday modeller üzerinden en düşük hatayı veren (final modeli oluşturulup test seti incelendiğinde buradaki en düşük hatayı veren) modeli seçip ilerlemek olacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mElasticNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mselection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cyclic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Linear regression with combined L1 and L2 priors as regularizer.\n",
       "\n",
       "Minimizes the objective function::\n",
       "\n",
       "        1 / (2 * n_samples) * ||y - Xw||^2_2\n",
       "        + alpha * l1_ratio * ||w||_1\n",
       "        + 0.5 * alpha * (1 - l1_ratio) * ||w||^2_2\n",
       "\n",
       "If you are interested in controlling the L1 and L2 penalty\n",
       "separately, keep in mind that this is equivalent to::\n",
       "\n",
       "        a * L1 + b * L2\n",
       "\n",
       "where::\n",
       "\n",
       "        alpha = a + b and l1_ratio = a / (a + b)\n",
       "\n",
       "The parameter l1_ratio corresponds to alpha in the glmnet R package while\n",
       "alpha corresponds to the lambda parameter in glmnet. Specifically, l1_ratio\n",
       "= 1 is the lasso penalty. Currently, l1_ratio <= 0.01 is not reliable,\n",
       "unless you supply your own sequence of alpha.\n",
       "\n",
       "Read more in the :ref:`User Guide <elastic_net>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "alpha : float, optional\n",
       "    Constant that multiplies the penalty terms. Defaults to 1.0.\n",
       "    See the notes for the exact mathematical meaning of this\n",
       "    parameter.``alpha = 0`` is equivalent to an ordinary least square,\n",
       "    solved by the :class:`LinearRegression` object. For numerical\n",
       "    reasons, using ``alpha = 0`` with the ``Lasso`` object is not advised.\n",
       "    Given this, you should use the :class:`LinearRegression` object.\n",
       "\n",
       "l1_ratio : float\n",
       "    The ElasticNet mixing parameter, with ``0 <= l1_ratio <= 1``. For\n",
       "    ``l1_ratio = 0`` the penalty is an L2 penalty. ``For l1_ratio = 1`` it\n",
       "    is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a\n",
       "    combination of L1 and L2.\n",
       "\n",
       "fit_intercept : bool\n",
       "    Whether the intercept should be estimated or not. If ``False``, the\n",
       "    data is assumed to be already centered.\n",
       "\n",
       "normalize : boolean, optional, default False\n",
       "    This parameter is ignored when ``fit_intercept`` is set to False.\n",
       "    If True, the regressors X will be normalized before regression by\n",
       "    subtracting the mean and dividing by the l2-norm.\n",
       "    If you wish to standardize, please use\n",
       "    :class:`sklearn.preprocessing.StandardScaler` before calling ``fit``\n",
       "    on an estimator with ``normalize=False``.\n",
       "\n",
       "precompute : True | False | array-like\n",
       "    Whether to use a precomputed Gram matrix to speed up\n",
       "    calculations. The Gram matrix can also be passed as argument.\n",
       "    For sparse input this option is always ``True`` to preserve sparsity.\n",
       "\n",
       "max_iter : int, optional\n",
       "    The maximum number of iterations\n",
       "\n",
       "copy_X : boolean, optional, default True\n",
       "    If ``True``, X will be copied; else, it may be overwritten.\n",
       "\n",
       "tol : float, optional\n",
       "    The tolerance for the optimization: if the updates are\n",
       "    smaller than ``tol``, the optimization code checks the\n",
       "    dual gap for optimality and continues until it is smaller\n",
       "    than ``tol``.\n",
       "\n",
       "warm_start : bool, optional\n",
       "    When set to ``True``, reuse the solution of the previous call to fit as\n",
       "    initialization, otherwise, just erase the previous solution.\n",
       "    See :term:`the Glossary <warm_start>`.\n",
       "\n",
       "positive : bool, optional\n",
       "    When set to ``True``, forces the coefficients to be positive.\n",
       "\n",
       "random_state : int, RandomState instance or None, optional, default None\n",
       "    The seed of the pseudo random number generator that selects a random\n",
       "    feature to update.  If int, random_state is the seed used by the random\n",
       "    number generator; If RandomState instance, random_state is the random\n",
       "    number generator; If None, the random number generator is the\n",
       "    RandomState instance used by `np.random`. Used when ``selection`` ==\n",
       "    'random'.\n",
       "\n",
       "selection : str, default 'cyclic'\n",
       "    If set to 'random', a random coefficient is updated every iteration\n",
       "    rather than looping over features sequentially by default. This\n",
       "    (setting to 'random') often leads to significantly faster convergence\n",
       "    especially when tol is higher than 1e-4.\n",
       "\n",
       "Attributes\n",
       "----------\n",
       "coef_ : array, shape (n_features,) | (n_targets, n_features)\n",
       "    parameter vector (w in the cost function formula)\n",
       "\n",
       "sparse_coef_ : scipy.sparse matrix, shape (n_features, 1) |             (n_targets, n_features)\n",
       "    ``sparse_coef_`` is a readonly property derived from ``coef_``\n",
       "\n",
       "intercept_ : float | array, shape (n_targets,)\n",
       "    independent term in decision function.\n",
       "\n",
       "n_iter_ : array-like, shape (n_targets,)\n",
       "    number of iterations run by the coordinate descent solver to reach\n",
       "    the specified tolerance.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> from sklearn.linear_model import ElasticNet\n",
       ">>> from sklearn.datasets import make_regression\n",
       "\n",
       ">>> X, y = make_regression(n_features=2, random_state=0)\n",
       ">>> regr = ElasticNet(random_state=0)\n",
       ">>> regr.fit(X, y)  # doctest: +NORMALIZE_WHITESPACE\n",
       "ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=0, selection='cyclic', tol=0.0001, warm_start=False)\n",
       ">>> print(regr.coef_) # doctest: +ELLIPSIS\n",
       "[18.83816048 64.55968825]\n",
       ">>> print(regr.intercept_) # doctest: +ELLIPSIS\n",
       "1.451...\n",
       ">>> print(regr.predict([[0, 0]])) # doctest: +ELLIPSIS\n",
       "[1.451...]\n",
       "\n",
       "\n",
       "Notes\n",
       "-----\n",
       "To avoid unnecessary memory duplication the X argument of the fit method\n",
       "should be directly passed as a Fortran-contiguous numpy array.\n",
       "\n",
       "See also\n",
       "--------\n",
       "ElasticNetCV : Elastic net model with best model selection by\n",
       "    cross-validation.\n",
       "SGDRegressor: implements elastic net regression with incremental training.\n",
       "SGDClassifier: implements logistic regression with elastic net penalty\n",
       "    (``SGDClassifier(loss=\"log\", penalty=\"elasticnet\")``).\n",
       "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     Lasso\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?ElasticNet #buradaki l1 ration parametresi, l1 in uygulanma oranı. bunu ileri seviyeler için değiştirme yapılabilir, alpha gibi aralık verilebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
